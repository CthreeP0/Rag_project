{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import re\n",
    "import time\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"FYP-Goo\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.environ.get('LANGCHAIN_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"GooYeJui.pdf\", extract_images=True)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Profile Summary\\nIndustry ExperienceRelevant Skills\\nGOO YE JUI\\nA recent graduate with a strong foundation in both front-end and back-end development, combined with a\\npassion for innovation and a commitment to making lives better through technology. Eager to contribute to\\nthe vision of Unit Nukleus GovTech by leveraging technical expertise to empower the nation and enhance\\ndigital government services. \\nFull-stack web development (HTML 5, CSS,\\nJavaScript, PHP, SQL, Python, .NET, React)\\nNatural Language Processing: spaCy, NLTK,\\nTensorFlow, PyTorch\\nGenerative AI related : LangChain, Llama\\nIndex\\nPetronas Digital Sdn Bhd - Data Science Intern Sept 2023 - Jun 2024\\nDeveloped (in 2 months) an Generative AI Based Resume Parser for Group HRM. The AI-powered parser\\nautomates the extraction and parsing of candidate information from resumes, saving HR professionals\\nvaluable time and effort in manually reviewing and categorizing resumes. Responsible for all frontend,\\nbackend and deployment-related matters, including backend architecture. Leveraged the capabilities of\\nOpenAI’s GPT models and traditional NLP libraries.\\nInvolved in the development of Applicant Tracking System that tracks each and every phases of the\\nrecruitment process. It is developed using Django as backend, HTML/CSS as frontend and PostgreSQL as\\ndatabase. yjyejui626@gmail.com +60184040438 14000, Bukit Mertajam, Penang\\nlinkedin.com/in/goo-ye-jui-8b2629159/ github.com/yejui626\\nPersonal Skills\\nTime Management\\nCollaboration\\nAdaptability\\nLeadership\\nCommunication\\nEducation\\nUniversiti Teknologi Malaysia          CGPA : 3.97 2020 - 2024\\nBachelor Of Computer Science (Data Engineering) With Honours\\nUniversiti Teknologi Malaysia          CGPA : 3.78 2019 - 2020\\nFoundation in Science \\nLanguage\\nEnglish Mandarin Malay French', metadata={'source': 'GooYeJui.pdf', 'page': 0}),\n",
       " Document(page_content='ChatGPT Sentiment Analysis with Django\\nDeveloped a web application that monitors and analyzes social media data from Reddit to understand public\\nopinion and sentiment on ChatGPT. Leveraged Python as the main programming language, along with  \\nMongoDB as the database, Django as the backend, and HTML/CSS as the frontend.May 2023 - July 2023\\nDeveloped a WordPress based e-commerce website for medubooks.com and tdiacademy21.com. Tailored the\\ndesign and user experience based on the brand’s identity and customer needs. Leveraging HTML, CSS and\\nJavaScript to deliver responsive and visually captivating elements and backend knowledge to implement\\nfunctions like search bar improvements, conditional promotions, and payment gateway integrations.July 2021 - Present WordPress FreelancePersonal Projects\\nQuotation Management SystemSept 2022 - Nov 2022\\nDeveloped a web-based quotation management system which manages the quotation process of Powerec\\nTechnology Service. The system was developed using HTML, CSS, JavaScript, PHP, and SQL to implement the\\nfrontend and backend functionalities of the system. \\nE- commerce ERP SystemMay 2023 - July 2023\\nDeveloped an E-commerce ERP system for TSK Online Shopping System by Intec Precision Engineering Sdn\\nBhd to streamlines its order management, inventory control, shipment arrangement, tracking, and overall\\nsupply chain efficiency using Laravel, MySQL, HTML and CSS. \\nRoom & Rental Management SystemMay 2023 - July 2023\\nDeveloped an Room Rental Management System for Akmal Rentals to manage their room rental business. It\\nincludes 7 modules to manage landlords, tenants, floors, rooms, transactions, inventory, and cleaner\\nattendance. The system is developed using Microsoft SQL Server as the database, Microsoft .NET MVC\\nFramework as the backend, and HTML, CSS, and JavaScript as the frontend.\\nCertifications\\nMicrosoft Certified: Azure AI Fundamentals | Jan 2023\\nGoogle Data Analytics Certificate by Coursera | August 2023\\nAlteryx Foundational Micro-Credential | Dec 2022\\nAlteryx Designer Core Certification | Dec 2022\\nAWS Academy Graduate - AWS Academy Cloud Foundations | Nov 2022\\nAWS Academy Graduate - AWS Academy Machine Learning Foundations | Dec 2022\\nAWS Academy Graduate - AWS Academy Data Analytics | Dec 2022\\nAWS Academy Graduate - AWS Academy Machine Learning for Natural Language Processing |\\nJune 2023\\nAWS Academy Graduate - AWS Academy Data Engineering | June 2023\\nAWS Academy Graduate - AWS Academy Cloud Web Application Builder | June 2023\\nAWS Academy Graduate - AWS Academy Cloud Data Pipeline Builder | June 2023', metadata={'source': 'GooYeJui.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "class Candidate(BaseModel):\n",
    "    \"\"\"Information about a candidate from his/her resume.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "\n",
    "    name: Optional[str] = Field(..., description=\"The name of the candidate\")\n",
    "    phone_number: Optional[str] = Field(\n",
    "        ..., description=\"The phone number of the candidate\"\n",
    "    )\n",
    "    email: Optional[str] = Field(\n",
    "        ..., description=\"The email of the candidate\"\n",
    "    )\n",
    "    local: Optional[str] = Field(\n",
    "        ..., description=\"Is the candidate Malaysian(Yes or No)?\"\n",
    "    )\n",
    "    expected_salary: Optional[str] = Field(\n",
    "        ..., description=\"Candidate's expected salary in RM if known. (If the currency is Ringgit Malaysia, assign the numerical value or range values only Eg:'3000-3100'. If in other currency, assign alongside currency)\"\n",
    "    )\n",
    "    current_location: Optional[List] = Field(\n",
    "        ..., description=\"Candidate's current location if known. If the candidate does not mention the country, assign the country based on the state and city. Return it in a python dict format with these three keys, example: {'Country': '', 'State': '', 'City': ''} \"\n",
    "    )\n",
    "    education_background: Optional[List] = Field(\n",
    "        ..., description=\"Every single candidate's education background. (field_of_study, level (always expand to long forms), cgpa (Example: 3.5/4.0), university, start_date, year_of_graduation (Year in 4-digits only, remove month). All in a python dict format.\"\n",
    "    )\n",
    "    professional_certificate: Optional[List] = Field(\n",
    "        ..., description=\"Candidate's professional certificates stated in the resume, return each certificate as a string in a python list.\"\n",
    "    )\n",
    "    skill_group: Optional[List] = Field(\n",
    "        ..., description=\"Every single candidate's skill groups stated in the resume, return each skills as a string in a python list.\"\n",
    "    )\n",
    "    technology_programs_tool: Optional[List] = Field(\n",
    "        ..., description=\"Every single candidate's Technology (Tools, Program, System) related to job title stated in the resume, return each technology as a string in a python list.\"\n",
    "    )\n",
    "    language: Optional[List] = Field(\n",
    "        ..., description=\"Languages that is stated in the resume, return each language as a string in a python list.\"\n",
    "    )\n",
    "    previous_job_roles: Optional[List] = Field(\n",
    "        ..., description=\"Every single one of the candidate's (job_title, job_company, Industries (strictly classify according to to The International Labour Organization), start_date and end_date (only assign date time format if available. Do not assign duration), job_location, job_duration (return the job_duration in years), return in a python dict format.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from datetime import datetime\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm with 20 years experience in the recruiting industry. You will be provided with candidate's resume. \\n\"\n",
    "            \"Extract relevant candidate's information mentioned in the following candidate's resume together with their properties. \\n\"\n",
    "            \"1) Please provide an accurate answers, no guessing. \\n\"\n",
    "            \"2) Please return 'N/A' only if the information is not mentioned. \\n\"\n",
    "            \"3) No need to return any reasoning as this is only for extraction of information. \\n\"\n",
    "            \"4) Extracted Properties of all Start date and End date: \\n\"\n",
    "            \"* if the month is not stated, assume that start/end date is in the middle of the year. \\n\"\n",
    "            \"* should never include english words such as 'months', 'years', 'days'. \\n\"\n",
    "            \"* Instead, dates should be dates converted to the following format: \\n\"\n",
    "            \"* date values assigned are strictly in Python datetime format. \\n\"\n",
    "            \"\"\"Strict Format of either one: \n",
    "                YYYY\n",
    "                YYYY-MM or YYYYMM\n",
    "                YYYY-MM-DD or YYYYMMDD\n",
    "            6) Ensure that for any duration (year) calculation: \n",
    "            * Any end date that indicates \"Present\", refers to today's date, which is {current_date}. \n",
    "            * Do not assume the work experiences are continuous without breaks.\n",
    "            * Method of duration calculation: Subtract the end date from start date to get the number of months. Finally sum up all relevant durations and convert to years. \n",
    "            * Triple check your calculations. \",\"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0.3)\n",
    "runnable = prompt | llm.with_structured_output(schema=Candidate)\n",
    "result = runnable.invoke({\"text\": pages,\"current_date\":datetime.now()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Candidate(name='GOO YE JUI', phone_number='+60184040438', email='yjyejui626@gmail.com', local='N/A', expected_salary='N/A', current_location=[{'Country': 'Malaysia', 'State': 'Penang', 'City': 'Bukit Mertajam'}], education_background=[{'field_of_study': 'Bachelor Of Computer Science (Data Engineering)', 'level': \"Bachelor's Degree\", 'cgpa': '3.97', 'university': 'Universiti Teknologi Malaysia', 'start_date': '2020', 'year_of_graduation': '2024'}, {'field_of_study': 'Foundation in Science', 'level': 'Foundation', 'cgpa': '3.78', 'university': 'Universiti Teknologi Malaysia', 'start_date': '2019', 'year_of_graduation': '2020'}], professional_certificate=['Microsoft Certified: Azure AI Fundamentals', 'Google Data Analytics Certificate by Coursera', 'Alteryx Foundational Micro-Credential', 'Alteryx Designer Core Certification', 'AWS Academy Graduate - AWS Academy Cloud Foundations', 'AWS Academy Graduate - AWS Academy Machine Learning Foundations', 'AWS Academy Graduate - AWS Academy Data Analytics', 'AWS Academy Graduate - AWS Academy Machine Learning for Natural Language Processing', 'AWS Academy Graduate - AWS Academy Data Engineering', 'AWS Academy Graduate - AWS Academy Cloud Web Application Builder', 'AWS Academy Graduate - AWS Academy Cloud Data Pipeline Builder'], skill_group=['Full-stack web development', 'Natural Language Processing', 'Generative AI'], technology_programs_tool=['HTML 5', 'CSS', 'JavaScript', 'PHP', 'SQL', 'Python', '.NET', 'React', 'spaCy', 'NLTK', 'TensorFlow', 'PyTorch', 'LangChain', 'Llama', 'Django', 'PostgreSQL', 'OpenAI GPT', 'Laravel', 'MySQL', 'Microsoft SQL Server', '.NET MVC Framework'], language=['English', 'Mandarin', 'Malay', 'French'], previous_job_roles=[{'job_title': 'Data Science Intern', 'job_company': 'Petronas Digital Sdn Bhd', 'Industries': 'Information Technology', 'start_date': '2023-09', 'end_date': '2024-06', 'job_location': 'N/A'}])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'GOO YE JUI',\n",
       " 'phone_number': '+60184040438',\n",
       " 'email': 'yjyejui626@gmail.com',\n",
       " 'local': 'N/A',\n",
       " 'expected_salary': 'N/A',\n",
       " 'current_location': [{'Country': 'Malaysia',\n",
       "   'State': 'Penang',\n",
       "   'City': 'Bukit Mertajam'}],\n",
       " 'education_background': [{'field_of_study': 'Bachelor Of Computer Science (Data Engineering)',\n",
       "   'level': \"Bachelor's Degree\",\n",
       "   'cgpa': '3.97',\n",
       "   'university': 'Universiti Teknologi Malaysia',\n",
       "   'start_date': '2020',\n",
       "   'year_of_graduation': '2024'},\n",
       "  {'field_of_study': 'Foundation in Science',\n",
       "   'level': 'Foundation',\n",
       "   'cgpa': '3.78',\n",
       "   'university': 'Universiti Teknologi Malaysia',\n",
       "   'start_date': '2019',\n",
       "   'year_of_graduation': '2020'}],\n",
       " 'professional_certificate': ['Microsoft Certified: Azure AI Fundamentals',\n",
       "  'Google Data Analytics Certificate by Coursera',\n",
       "  'Alteryx Foundational Micro-Credential',\n",
       "  'Alteryx Designer Core Certification',\n",
       "  'AWS Academy Graduate - AWS Academy Cloud Foundations',\n",
       "  'AWS Academy Graduate - AWS Academy Machine Learning Foundations',\n",
       "  'AWS Academy Graduate - AWS Academy Data Analytics',\n",
       "  'AWS Academy Graduate - AWS Academy Machine Learning for Natural Language Processing',\n",
       "  'AWS Academy Graduate - AWS Academy Data Engineering',\n",
       "  'AWS Academy Graduate - AWS Academy Cloud Web Application Builder',\n",
       "  'AWS Academy Graduate - AWS Academy Cloud Data Pipeline Builder'],\n",
       " 'skill_group': ['Full-stack web development',\n",
       "  'Natural Language Processing',\n",
       "  'Generative AI'],\n",
       " 'technology_programs_tool': ['HTML 5',\n",
       "  'CSS',\n",
       "  'JavaScript',\n",
       "  'PHP',\n",
       "  'SQL',\n",
       "  'Python',\n",
       "  '.NET',\n",
       "  'React',\n",
       "  'spaCy',\n",
       "  'NLTK',\n",
       "  'TensorFlow',\n",
       "  'PyTorch',\n",
       "  'LangChain',\n",
       "  'Llama',\n",
       "  'Django',\n",
       "  'PostgreSQL',\n",
       "  'OpenAI GPT',\n",
       "  'Laravel',\n",
       "  'MySQL',\n",
       "  'Microsoft SQL Server',\n",
       "  '.NET MVC Framework'],\n",
       " 'language': ['English', 'Mandarin', 'Malay', 'French'],\n",
       " 'previous_job_roles': [{'job_title': 'Data Science Intern',\n",
       "   'job_company': 'Petronas Digital Sdn Bhd',\n",
       "   'Industries': 'Information Technology',\n",
       "   'start_date': '2023-09',\n",
       "   'end_date': '2024-06',\n",
       "   'job_location': 'N/A'}]}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert Candidate object to dictionary\n",
    "candidate_dict = result.dict()\n",
    "\n",
    "# Create DataFrame with one row using the dictionary\n",
    "df = pd.DataFrame([candidate_dict])\n",
    "df.to_excel('results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'field_of_study': 'Bachelor Of Computer Science (Data Engineering)', 'level': \"Bachelor's Degree\", 'cgpa': 3.97, 'university': 'Universiti Teknologi Malaysia', 'start_date': '2020', 'year_of_graduation': '2024'}, {'field_of_study': 'Foundation in Science', 'level': 'Foundation', 'cgpa': 3.78, 'university': 'Universiti Teknologi Malaysia', 'start_date': '2019', 'year_of_graduation': '2020'}]\n"
     ]
    }
   ],
   "source": [
    "print(df['education_background'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9zuTpclGO06S'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import secrets,string\n",
    "batch_token = \"\".join(secrets.choice(string.ascii_letters + string.digits) for _ in range(12))\n",
    "batch_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email</th>\n",
       "      <th>local</th>\n",
       "      <th>expected_salary</th>\n",
       "      <th>current_location</th>\n",
       "      <th>education_background</th>\n",
       "      <th>professional_certificate</th>\n",
       "      <th>skill_group</th>\n",
       "      <th>technology_programs_tool</th>\n",
       "      <th>language</th>\n",
       "      <th>previous_job_roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOO YE JUI</td>\n",
       "      <td>60184040438</td>\n",
       "      <td>yjyejui626@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'Country': 'Malaysia', 'State': 'Penang', 'C...</td>\n",
       "      <td>[{'field_of_study': 'Bachelor Of Computer Scie...</td>\n",
       "      <td>['Microsoft Certified: Azure AI Fundamentals',...</td>\n",
       "      <td>['Full-stack web development', 'Natural Langua...</td>\n",
       "      <td>['HTML 5', 'CSS', 'JavaScript', 'PHP', 'SQL', ...</td>\n",
       "      <td>['English', 'Mandarin', 'Malay', 'French']</td>\n",
       "      <td>[{'job_title': 'Data Science Intern', 'job_com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  phone_number                 email  local  expected_salary  \\\n",
       "0  GOO YE JUI   60184040438  yjyejui626@gmail.com    NaN              NaN   \n",
       "\n",
       "                                    current_location  \\\n",
       "0  [{'Country': 'Malaysia', 'State': 'Penang', 'C...   \n",
       "\n",
       "                                education_background  \\\n",
       "0  [{'field_of_study': 'Bachelor Of Computer Scie...   \n",
       "\n",
       "                            professional_certificate  \\\n",
       "0  ['Microsoft Certified: Azure AI Fundamentals',...   \n",
       "\n",
       "                                         skill_group  \\\n",
       "0  ['Full-stack web development', 'Natural Langua...   \n",
       "\n",
       "                            technology_programs_tool  \\\n",
       "0  ['HTML 5', 'CSS', 'JavaScript', 'PHP', 'SQL', ...   \n",
       "\n",
       "                                     language  \\\n",
       "0  ['English', 'Mandarin', 'Malay', 'French']   \n",
       "\n",
       "                                  previous_job_roles  \n",
       "0  [{'job_title': 'Data Science Intern', 'job_com...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dict = pd.read_excel('results.xlsx',index_col=0)\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse range inputs \n",
    "def parse_range(input_string):\n",
    "    \"\"\"\n",
    "    Parses the range string.\n",
    "\n",
    "    Args:\n",
    "    input_string: A string containing formats like \"<5.6\", \">5\", \"=5.0\", or \"2.0-5\".\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the lower limit, upper limit, and condition.\n",
    "    \"\"\"\n",
    "    match = re.match(r'^\\s*(<|>|=)?\\s*([0-9]+(?:\\.[0-9]+)?)(?:\\s*-\\s*([0-9]+(?:\\.[0-9]+)?))?\\s*$', input_string)\n",
    "    condition = \"\"\n",
    "    in_threshold_lower_limit = 0\n",
    "    in_threshold_upper_limit = 99999\n",
    "\n",
    "    if match:\n",
    "        condition = match.group(1)\n",
    "        values = match.group(2)\n",
    "\n",
    "        if condition == \"<\":\n",
    "            in_threshold_upper_limit = float(values)\n",
    "        elif condition == \">\":\n",
    "            in_threshold_lower_limit = float(values)\n",
    "        elif condition == \"=\":\n",
    "            in_threshold_lower_limit = in_threshold_upper_limit = float(values)\n",
    "        elif match.group(3): # range \n",
    "            condition = \"range\"\n",
    "            in_threshold_lower_limit = float(values)\n",
    "            in_threshold_upper_limit = float(match.group(3))\n",
    "        else: # exact value, same as \"=\"\n",
    "            condition = \"=\"\n",
    "            in_threshold_lower_limit = in_threshold_upper_limit = float(values)\n",
    "        # print(f\"\\tLower Limit: {in_threshold_lower_limit}, Upper Limit: {in_threshold_upper_limit}, Condition: {condition}\")\n",
    "        \n",
    "    else:\n",
    "        # print (f\"\\tVal = {input_string}  Parse Range funtion detected: Invalid input format\")\n",
    "        in_threshold_lower_limit, in_threshold_upper_limit = 0, 9999999\n",
    "\n",
    "    return in_threshold_lower_limit, in_threshold_upper_limit, condition\n",
    "    # # Example usage\n",
    "    # input_string = \"11.59-888\"\n",
    "    # lower_limit, upper_limit, condition = parse_range(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from edu ChatCompletion(id='chatcmpl-9LUAnl6RssJDRM1F1beTBp2XDF7dl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Step 1: The candidate's field of study is in Applied Data Analytics at the Master's level, which is a closely related field to Data Science. However, it is not a Bachelor's Degree in Data Science or Computer Science as preferred. There is a minor relevance between the candidate's field of study and the job title of Executive (Data Scientist).\\n\\nStep 2: Education Background Rating: [[5]].\", role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content=\"Step 1: The candidate's field of study is in Applied Data Analytics at the Master's level, which is a related field to Data Science. However, the candidate's education background is at the Master's level, not at the Bachelor's level as required. Additionally, the job title is for an Executive (Data Scientist), which may require a more specialized focus on Data Science or Computer Science.\\n\\nStep 2: \\nEducation Background Rating: [[5]].\", role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='Step 1: The candidate\\'s field of study is in Applied Data Analytics at the Master\\'s level, which is a closely related field to Data Science. However, the candidate\\'s education background is at the Master\\'s level, whereas the job requires a Bachelor\\'s Degree. Additionally, the specific focus on \"Applied Data Analytics\" may not fully align with the broader scope of Data Science.\\n\\nEducation Background Rating: [[7]].', role='assistant', function_call=None, tool_calls=None))], created=1714907901, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=258, prompt_tokens=553, total_tokens=811))\n",
      "Candidate: Ang Teik Hun\t\t1. EDU Score:12/20\t C: refer data_dict E: Bachelor's Degree in Data Science or Computer Science\t \n",
      "Response from edu ChatCompletion(id='chatcmpl-9LUApU1thUGm4xtjjTqoDMSWXK16m', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Education Background Rating: [[7]].\\n\\nThe candidate's field of study is Bachelor of Computer Science with a specialization in Data Engineering, which is closely related to the preferred field of study in Data Science or Computer Science. However, the title of Executive (Data Scientist) may require a more specific focus on Data Science rather than Data Engineering. Despite this minor discrepancy, the candidate's education background aligns well with the job title and preferred field of study.\", role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='Education Background Rating: [[7]].\\n\\nThe candidate\\'s field of study, \"Bachelor Of Computer Science (Data Engineering)\", is closely related to both Data Science and Computer Science. Although the specific focus on Data Engineering may not align perfectly with the job title of \"Data Scientist\", it still demonstrates a strong foundation in the required technical skills. There are no major errors or omissions in the candidate\\'s education background, and the minor discrepancy in the specialization can be overlooked.', role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='Step 1 : The candidate\\'s education background includes a Bachelor of Computer Science with a specialization in Data Engineering, which is closely related to the preferred field of study in Data Science or Computer Science. However, the title of \"Data Scientist\" typically requires a more specific focus on data analysis, machine learning, and statistical modeling, which may not be fully covered in the candidate\\'s field of study. Additionally, there is a Foundation in Science background which is not directly related to Data Science or Computer Science.\\n\\nStep 2: \\n\\nEducation Background Rating: [[7]].', role='assistant', function_call=None, tool_calls=None))], created=1714907903, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=295, prompt_tokens=614, total_tokens=909))\n",
      "Candidate: GOO YE JUI\t\t1. EDU Score:14/20\t C: refer data_dict E: Bachelor's Degree in Data Science or Computer Science\t \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "def evaluate_education_background(row, input, weightage):\n",
    "    max_retries = 5\n",
    "    retry_count = 0\n",
    "    \n",
    "    try:\n",
    "        edu_prompt_system = f\"\"\"[Instruction] You will be provided with details such as the preferred field of study, job_title, and the candidate's field of study.\n",
    "        Please act as an impartial judge and evaluate the candidate's field of study based on the job_title and preferred education background. For this evaluation, you should primarily consider the following accuracy:\n",
    "        [Accuracy]\n",
    "        Score 1: The candidate's field of study is completely unrelated to {input} and the job_title stated.\n",
    "        Score 3: The candidate's field of study has minor relevance but does not align with {input} and the job_title stated.\n",
    "        Score 5: The candidate's field of study has moderate relevance but contains inaccuracies to {input} and the job_title stated.\n",
    "        Score 7: The candidate's field of study aligns with {input} and the job_title stated but has minor errors or omissions on either one of them.\n",
    "        Score 10: The candidate's field of study is completely accurate and aligns very well with {input} and the job_title stated.\n",
    "        \n",
    "        [Rules]\n",
    "        1. If the candidate has several education background, you should always consider the most related to {input} and the job_title only.\n",
    "        2. You should always ignore those that are unrelated to {input} and the job_title and make sure they do not affect the total scoring.\n",
    "        3. You should only assess the candidate's Field of Study and it's level. Ignore any other criterias.\n",
    "\n",
    "        [Steps]\n",
    "        Step 1 : Start the evaluation by giving reasons, Be as objective as possible.\n",
    "        Step 2 : You must rate the candidate on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", \n",
    "        for example:\n",
    "        \"Education Background Rating: [[6]].\n",
    "\n",
    "        [Question]\n",
    "        How will you rate the candidate's education background based on the provided job_title with preferred education background?\n",
    "        \"\"\"\n",
    "\n",
    "        edu_prompt_user = f\"\"\"\n",
    "        Preferred Field of Study: {input}\n",
    "        \n",
    "        job_title: {job_title}\n",
    "\n",
    "        [The Start of Candidate's Education Background]\n",
    "        {row['education_background']}\n",
    "        [The End of Candidate's Education Background]\n",
    "        \"\"\"\n",
    "        \n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": edu_prompt_system},\n",
    "                {\"role\": \"user\", \"content\": edu_prompt_user}\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            temperature=0.3,\n",
    "            n=3,\n",
    "        )\n",
    "        \n",
    "        print(\"Response from edu\", response)\n",
    "        \n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"OpenAI rate limit exceeded. Pausing for one minute before resuming... (From RateLimitError)\")\n",
    "        print(e)\n",
    "        time.sleep(30)\n",
    "        retry_count += 1\n",
    "\n",
    "        if retry_count >= max_retries:\n",
    "            print(\"Exceeded maximum retries for evaluating education background.... (From RateLimitError)\")\n",
    "            return response\n",
    "    \n",
    "    # Extract the number using regex\n",
    "    def extract_gpt_response_rating(response):\n",
    "        ratings = []\n",
    "        pattern = r'\\[\\[([\\d]+)\\]\\]'\n",
    "\n",
    "        for i in range(len(response.choices)):\n",
    "            match = re.search(pattern, response.choices[i].message.content)\n",
    "            if match:\n",
    "                rating = int(match.group(1))\n",
    "                ratings.append(rating)\n",
    "            else:\n",
    "                # ratings = 0\n",
    "                ratings.append(0)\n",
    "        return ratings\n",
    "    \n",
    "    # Calculate average rating\n",
    "    def calculate_average_rating(ratings):\n",
    "        if not ratings:\n",
    "            return 0\n",
    "        return round(sum(ratings) / len(ratings))\n",
    "\n",
    "    # Calculate weighted score\n",
    "    def calculate_weighted_score(average_rating, weightage):\n",
    "        if average_rating is None:\n",
    "            return 0\n",
    "        return round(average_rating / 10 * weightage)\n",
    "            \n",
    "    edu_rating = extract_gpt_response_rating(response)\n",
    "    average_rating = calculate_average_rating(edu_rating)\n",
    "    edu_weighted_score = calculate_weighted_score(average_rating, weightage)\n",
    "    \n",
    "    print(f\"Candidate: {row['name']}\\t\\t1. EDU Score:{edu_weighted_score}/{weightage}\\t C: refer data_dict E: {input}\\t \")\n",
    "    \n",
    "    return edu_weighted_score\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'df' is your dataframe containing the data\n",
    "# input and weightage are assumed to be defined earlier\n",
    "input = \"Bachelor's Degree in Data Science or Computer Science\"\n",
    "job_title = \"Executive (Data Scientist)\"\n",
    "data_dict['education_background_score'] = data_dict.apply(lambda row: evaluate_education_background(row, input, 20), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['education_background'][0] = '[{\\'field_of_study\\': \\'Applied Data Analytics\\', \\'level\\': \"Master\\'s\", \\'cgpa\\': \\'6.42\\', \\'university\\': \\'Australian National University\\', \\'Start Date\\': \\'2021-07\\', \\'year_of_graduation\\': \\'2022\\'}]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGPA method 2: Getting latest available cgpa\n",
      "[{'field_of_study': 'Applied Data Analytics', 'level': \"Master's\", 'cgpa': '6.42', 'university': 'Australian National University', 'Start Date': '2021-07', 'year_of_graduation': '2022'}]\n",
      "6.42\n",
      "6.42 4.0\n",
      "normalised cgpa:  6.42, raw cgpa extracted: 6.42\n",
      "Candidate: Ang Teik Hun\t\t 2. CGPA Score:20.0/20\t C CGPA(normalised): 6.42 VS E: 3.5 \t \n",
      "CGPA method 2: Getting latest available cgpa\n",
      "[{'field_of_study': 'Bachelor Of Computer Science (Data Engineering)', 'level': \"Bachelor's Degree\", 'cgpa': '3.97', 'university': 'Universiti Teknologi Malaysia', 'start_date': '2020', 'year_of_graduation': '2024'}, {'field_of_study': 'Foundation in Science', 'level': 'Foundation', 'cgpa': '3.78', 'university': 'Universiti Teknologi Malaysia', 'start_date': '2019', 'year_of_graduation': '2020'}]\n",
      "3.97\n",
      "3.97 4.0\n",
      "normalised cgpa:  3.97, raw cgpa extracted: 3.97\n",
      "Candidate: GOO YE JUI\t\t 2. CGPA Score:20.0/20\t C CGPA(normalised): 3.97 VS E: 3.5 \t \n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "def evaluate_cgpa(data_dict,input_cgpa, weightage):\n",
    "    out_weighted_cgpa_score = 0.0\n",
    "    c_cgpa = 0 #total \n",
    "\n",
    "    def get_normalize_cgpa(cgpa_str,standard_scale = 4.0):\n",
    "        # Regex pattern to match CGPA values and their max scales\n",
    "        pattern = r'(\\d+(?:\\.\\d+)?)(?:/(\\d+(?:\\.\\d+)?))?'\n",
    "\n",
    "        # Searching for the pattern in the text\n",
    "        match = re.search(pattern, cgpa_str)\n",
    "        if match:\n",
    "            cgpa = float(match.group(1))\n",
    "            max_cgpa = float(match.group(2)) if match.group(2) else standard_scale\n",
    "\n",
    "            print(cgpa,max_cgpa)\n",
    "\n",
    "            # Normalize CGPA to the standard scale\n",
    "            normalized_cgpa = (cgpa / max_cgpa) * standard_scale\n",
    "            print (f\"\"\"normalised cgpa:  {normalized_cgpa}, raw cgpa extracted: {cgpa_str}\"\"\")\n",
    "            return normalized_cgpa\n",
    "        else: # if N/A in resume, cpga -> 0.0 \n",
    "            print (\"normalised cgpa:  CPGA not found. Default CGPA = 0.0/4.0\")\n",
    "            return float(\"0\")\n",
    "\n",
    "\n",
    "    if 'education_background' not in data_dict:\n",
    "        print(f\"Candidate: {data_dict['name']}\\t\\t 2. CGPA Score:{out_weighted_cgpa_score}/{weightage}\\t C CGPA(normalised): {c_cgpa} VS E: {input_cgpa} \\t \")\n",
    "        return 0.4 * weightage\n",
    "    else: \n",
    "        print (\"CGPA method 2: Getting latest available cgpa\")\n",
    "        data_list = ast.literal_eval(data_dict.education_background)\n",
    "        print(data_list)\n",
    "        data_list.sort(key=lambda x: int(x['year_of_graduation']), reverse=True)\n",
    "        print(data_list[0]['cgpa'])\n",
    "        if data_list[0]['cgpa']  != \"N/A\" :\n",
    "            c_cgpa = get_normalize_cgpa(data_list[0]['cgpa'])\n",
    "\n",
    "        if float(c_cgpa) >= float(input_cgpa):\n",
    "            out_weighted_cgpa_score = 1.0 * weightage\n",
    "        else:\n",
    "            out_weighted_cgpa_score = 0.4 * weightage\n",
    "        print(f\"Candidate: {data_dict['name']}\\t\\t 2. CGPA Score:{out_weighted_cgpa_score}/{weightage}\\t C CGPA(normalised): {c_cgpa} VS E: {input_cgpa} \\t \")\n",
    "\n",
    "    return out_weighted_cgpa_score\n",
    "\n",
    "input = \"3.5\"\n",
    "data_dict['cgpa_score'] = data_dict.apply(lambda row: evaluate_cgpa(row, input, 20), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = \"Executive (Data Scientist)\"\n",
    "job_description = \"\"\"Responsibilities:\n",
    "Lead and mentor a team of data scientists and analysts, providing guidance and support to ensure high-quality deliverables\n",
    "Collaborate with cross-functional teams to define data-driven strategies and objectives\n",
    "Develop advanced statistical models and machine learning algorithms to analyze and interpret complex datasets\n",
    "Design and implement data pipelines and workflows to streamline data collection, processing, and analysis\n",
    "Identify and explore new data sources and technologies to enhance our analytical capabilities\n",
    "Communicate findings and recommendations to key stakeholders through compelling visualizations, presentations, and reports\n",
    "Stay current with the latest developments in data science and technology, and proactively identify opportunities for innovation and improvement\n",
    "\"\"\"\n",
    "job_requirement = \"\"\"Qualifications:\n",
    "Bachelor's degree in Computer Science, Statistics, Mathematics, or a related field; advanced degree preferred\n",
    " years of experience in data science or a related field, with a proven track record of leading successful projects and initiatives\n",
    "Proficiency in programming languages such as Python, R, or SQL, and experience with data analysis and visualization libraries (e.g., pandas, scikit-learn, matplotlib, seaborn)\n",
    "Strong understanding of statistical methods, machine learning techniques, and data mining algorithms\n",
    "Experience with big data technologies (e.g., Hadoop, Spark) and cloud platforms (e.g., AWS, Azure, GCP) preferred\n",
    "Excellent communication and interpersonal skills, with the ability to effectively collaborate with cross-functional teams and communicate complex technical concepts to non-technical stakeholders\n",
    "Proven leadership abilities, with the ability to inspire and motivate team members to achieve common goals\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing skills from jobdescription ['Python', 'R', 'SQL', 'pandas', 'scikit-learn', 'matplotlib', 'seaborn', 'Hadoop', 'Spark', 'AWS', 'Azure', 'GCP', 'statistical methods', 'machine learning techniques', 'data mining algorithms', 'communication skills', 'leadership abilities']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<assess_criteria_class.JobParser at 0x28d20df2930>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from assess_criteria_class import JobParser\n",
    "\n",
    "\n",
    "JD = JobParser(job_title,job_description,job_requirement)\n",
    "JD_skills = JD.extract_additional_skills()\n",
    "JD_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing skills from jobdescription ['Python', 'R', 'SQL', 'pandas', 'scikit-learn', 'matplotlib', 'seaborn', 'Hadoop', 'Spark', 'AWS', 'Azure', 'GCP']\n",
      "[0.3, 1.0, 0.3, 0.3, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.3, 0.0, 0.3]\n",
      "Candidate: Ang Teik Hun\t\t3. SkillGroup Score:5.23/20\tC similairty score: 5.23 E: python \t \n",
      "printing skills from jobdescription ['Python', 'R', 'SQL', 'pandas', 'scikit-learn', 'matplotlib', 'seaborn', 'Hadoop', 'Spark', 'AWS', 'Azure', 'GCP', 'statistics', 'machine learning', 'data mining', 'communication', 'leadership']\n",
      "[0.3, 1.0, 0.3, 0.3, 0.0, 0.3, 0.0, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.0, 0.0, 0.3, 0.3, 0.3]\n",
      "Candidate: GOO YE JUI\t\t3. SkillGroup Score:5.44/20\tC similairty score: 5.44 E: python \t \n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from assess_criteria_class import JobParser\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_skill_groups(data_dict,input,weightage):\n",
    "    job_title = \"Executive (Data Scientist)\"\n",
    "    job_description = \"\"\"Responsibilities:\n",
    "    Lead and mentor a team of data scientists and analysts, providing guidance and support to ensure high-quality deliverables\n",
    "    Collaborate with cross-functional teams to define data-driven strategies and objectives\n",
    "    Develop advanced statistical models and machine learning algorithms to analyze and interpret complex datasets\n",
    "    Design and implement data pipelines and workflows to streamline data collection, processing, and analysis\n",
    "    Identify and explore new data sources and technologies to enhance our analytical capabilities\n",
    "    Communicate findings and recommendations to key stakeholders through compelling visualizations, presentations, and reports\n",
    "    Stay current with the latest developments in data science and technology, and proactively identify opportunities for innovation and improvement\n",
    "    \"\"\"\n",
    "    job_requirement = \"\"\"Qualifications:\n",
    "    Bachelor's degree in Computer Science, Statistics, Mathematics, or a related field; advanced degree preferred\n",
    "    years of experience in data science or a related field, with a proven track record of leading successful projects and initiatives\n",
    "    Proficiency in programming languages such as Python, R, or SQL, and experience with data analysis and visualization libraries (e.g., pandas, scikit-learn, matplotlib, seaborn)\n",
    "    Strong understanding of statistical methods, machine learning techniques, and data mining algorithms\n",
    "    Experience with big data technologies (e.g., Hadoop, Spark) and cloud platforms (e.g., AWS, Azure, GCP) preferred\n",
    "    Excellent communication and interpersonal skills, with the ability to effectively collaborate with cross-functional teams and communicate complex technical concepts to non-technical stakeholders\n",
    "    Proven leadership abilities, with the ability to inspire and motivate team members to achieve common goals\n",
    "    \"\"\"\n",
    "    JD = JobParser(job_title,job_description,job_requirement)\n",
    "    JD_skills = JD.extract_additional_skills()\n",
    "    result_list = [skill.strip().lower() for skill in input.split(\",\")]\n",
    "    data_dict_lower = [x.lower() for x in data_dict['technical_skill']]\n",
    "    # Convert all strings in the list to lowercase\n",
    "    jd_skills_lower = [x.lower() for x in JD_skills.jd_skills]\n",
    "            \n",
    "    #Define embeddings model\n",
    "    embeddings_model = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "\n",
    "    #Embeds both list\n",
    "    embedding1 = embeddings_model.embed_documents(data_dict_lower) #candidate skill groups\n",
    "    embedding2 = embeddings_model.embed_documents(jd_skills_lower+result_list) #required skill groups\n",
    "\n",
    "    #Calculate the cosine similarity score from embeddings\n",
    "    similarity_test = cosine_similarity(embedding1,embedding2)\n",
    "\n",
    "    def similarity_range_score(similarity_scores):\n",
    "        categorical_scores = []\n",
    "\n",
    "        for score in similarity_scores:\n",
    "            if score >= 0.88:\n",
    "                categorical_scores.append(1.0)\n",
    "            elif score >= 0.85:\n",
    "                categorical_scores.append(0.5)\n",
    "            elif score >= 0.8:\n",
    "                categorical_scores.append(0.3)\n",
    "            else:\n",
    "                categorical_scores.append(0.0)\n",
    "        print(categorical_scores)\n",
    "\n",
    "        return categorical_scores\n",
    "\n",
    "        \n",
    "    res = round(np.mean(similarity_range_score(similarity_test.max(axis=0)))*weightage,2)\n",
    "    \n",
    "    print(f\"Candidate: {data_dict['name']}\\t\\t3. SkillGroup Score:{res}/{weightage}\\tC similairty score: {res} E: {input} \\t \")\n",
    "        \n",
    "    return res\n",
    "\n",
    "input = \"python\"\n",
    "data_dict['technical_skills_score'] = data_dict.apply(lambda row: evaluate_skill_groups(row, input, 20), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'job_title': 'Data Scientist', 'job_company': 'Petroliam Nasional Berhad', 'Industries': 'Oil and Gas', 'start_date': '2020-11', 'end_date': '2021-07', 'job_location': 'KL', 'Job Duration (Years)': 0.6}, {'job_title': 'Tutor', 'job_company': 'Australian National University', 'Industries': 'Education', 'start_date': '2022-06', 'end_date': '2022-12', 'job_location': 'Canberra', 'Job Duration (Years)': 0.5}]\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['previous_job_roles'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_total_working_exp_years(data_dict, input_string, weightage):\n",
    "    \n",
    "    c_total_yr_exp, out_weighted_score = 0.0, 0.0\n",
    "\n",
    "    def parse_date(date_str):\n",
    "        # Handle other values gracefully\n",
    "        if date_str.lower() in [\"n/a\", \"none\"]:\n",
    "            return None\n",
    "        elif date_str.lower() in [ \"present\", \"current\", \"now\"]: \n",
    "            return datetime.now()     \n",
    "        # Expanded corrections for non-standard month abbreviations to standard ones\n",
    "        corrections = {\n",
    "            \"Jan\": \"Jan\", \"Feb\": \"Feb\", \"Mar\": \"Mar\", \"Apr\": \"Apr\",\n",
    "            \"May\": \"May\", \"Jun\": \"Jun\", \"Jul\": \"Jul\", \"Aug\": \"Aug\",\n",
    "            \"Sep\": \"Sep\", \"Sept\": \"Sep\",  # Both 'Sep' and 'Sept' to 'Sep'\n",
    "            \"Oct\": \"Oct\", \"Nov\": \"Nov\", \"Dec\": \"Dec\",\n",
    "            \"Mac\": \"Mar\",  # Non-standard, common in some regions\n",
    "            # Add additional non-standard abbreviations as needed\n",
    "        }\n",
    "        # Replace non-standard abbreviations with their standard equivalents\n",
    "        for incorrect, correct in corrections.items():\n",
    "            if incorrect in date_str:\n",
    "                date_str = date_str.replace(incorrect, correct)\n",
    "\n",
    "        # Extensive list of date formats to try parsing the date strings\n",
    "        date_formats = [\n",
    "            \"%Y\",\n",
    "            \"%B %Y\",  # Full month name and year\n",
    "            \"%m %Y\",\n",
    "            \"%d %m %Y\",\n",
    "            \"%d-%m-%Y\",\n",
    "            \"%Y-%m-%d\",\n",
    "            \"%b %Y\",  # Abbreviated month name and year\n",
    "            \"%Y-%m\",\n",
    "            \"%m-%Y\",\n",
    "            \"%d %B %Y\",\n",
    "            \"%d %b %Y\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "            \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "            \"%m/%d/%Y\",\n",
    "            \"%m/%d/%y\",\n",
    "            \"%d/%m/%Y\",\n",
    "            \"%d/%m/%y\",\n",
    "        ]\n",
    "\n",
    "        for fmt in date_formats:\n",
    "            try:\n",
    "                return datetime.strptime(date_str, fmt)\n",
    "            except ValueError:\n",
    "                continue  # If current format fails, try the next\n",
    "\n",
    "        # If all formats fail, print an error and return None\n",
    "        print(f\"Error parsing date '{date_str}': does not match expected formats.\")\n",
    "        return None\n",
    "    \n",
    "    def gpt_calc_total_exp():\n",
    "        # Check if 'previous_job_roles' exists and is a list\n",
    "        \n",
    "        total_duration = 0\n",
    "        for role in data_dict['previous_job_roles']:\n",
    "            try:\n",
    "                # Attempt to convert job duration to float and add to total\n",
    "                duration_str = role.get(\"job_duration\", \"0\")  # Default to \"0\" if not found\n",
    "                duration = float(duration_str)\n",
    "                total_duration += duration\n",
    "            except ValueError:\n",
    "                # Handle case where conversion to float fails\n",
    "                print(f\"Error converting job duration to float for role: {role.get('job_title')}. Skipping this entry.\")\n",
    "                continue  # Skip this entry and continue with the next\n",
    "        print (f\"gpt4 total yr: {total_duration}\")\n",
    "                \n",
    "        return round(total_duration, 2)\n",
    "\n",
    "    # Manual: Total duration\n",
    "    total_experience_gpt4 = gpt_calc_total_exp()\n",
    "    # Use parse_range to get the lower and upper limits and condition\n",
    "    in_threshold_lower_limit, in_threshold_upper_limit, condition = parse_range(input_string)\n",
    "    try:\n",
    "        c_total_yr_exp = float(total_experience_gpt4)\n",
    "        if c_total_yr_exp < in_threshold_lower_limit:\n",
    "            out_weighted_score = 0  # does not meet requirement\n",
    "        elif in_threshold_lower_limit <= c_total_yr_exp <= in_threshold_upper_limit:\n",
    "            out_weighted_score = 1.0 * weightage  # within range ir equal \n",
    "        elif c_total_yr_exp > in_threshold_upper_limit:\n",
    "            out_weighted_score = 0.5 * weightage  # overqualified\n",
    "        else:\n",
    "            out_weighted_score = 0\n",
    "        print(f\"Candidate: {data_dict['name']}\\t\\t4.Total years of experience Score:{out_weighted_score}/ {weightage}\\t C:{c_total_yr_exp}, Required years: {input_string}\\n \")\n",
    "    except ValueError:\n",
    "        # Handle the case where conversion to float fails\n",
    "        out_weighted_score = 0  \n",
    "    \n",
    "    return total_experience_gpt4,out_weighted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4 total yr: 17.0\n",
      "Candidate: GOO YE JUI\t\t4.Total years of experience Score:20.0/ 20\t C:17.0, Required years: python\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "input = \"python\"\n",
    "\n",
    "data_dict['previous_job_roles'][0] = data_dict['previous_job_roles'][0].replace(\"'\", '\"')\n",
    "data_dict['previous_job_roles'][0] = json.loads(data_dict['previous_job_roles'][0])\n",
    "data_dict[['work_experience_duration', 'work_experience_duration_score']] = data_dict.apply(lambda row: pd.Series(evaluate_total_working_exp_years(row, input, 20)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import math\n",
    "\n",
    "\n",
    "def evaluate_year_exp_role(data_dict, input, weightage):\n",
    "\n",
    "    def extract_yoer_similar(data_dict):\n",
    "        max_retries = 5\n",
    "        retry_count = 0 \n",
    "        try:\n",
    "            yoer_prompt_system = f\"\"\"[Instruction] \n",
    "            You will be provided with details such as the candidate's previous job roles. Please act as a hiring manager with 20 years experience to evaluate the candidate's previous job roles.\n",
    "            1. Identify job roles that are similar to {job_title}. You should also consider roles that are related to {job_title}.\n",
    "            2. Return all of the duration of the related job roles into a python list.\n",
    "            3. The output format should strictly follow the format in the example provided.\n",
    "            Example of the output: Total duration: [[2,3,4]]\n",
    "\n",
    "            [Question]\n",
    "            What are the job durations for the job roles that are related to {job_title} in the candidate's previous job experience?\n",
    "            \"\"\"\n",
    "\n",
    "            yoer_prompt_user = f\"\"\"\n",
    "            Candidate's Previous Job Roles: {data_dict[\"previous_job_roles\"]}\n",
    "            \"\"\"\n",
    "            client = OpenAI()\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo-0125\", # 3.5 turbo\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": yoer_prompt_system},\n",
    "                    {\"role\": \"user\", \"content\": yoer_prompt_user}\n",
    "                ],\n",
    "                temperature=0.3,\n",
    "            )\n",
    "            print(\"Response from yoer\",response)\n",
    "            return response.choices[0].message.content\n",
    "        except openai.RateLimitError as e:\n",
    "            print(f\"OpenAI rate limit exceeded. Pausing for one minute before resuming... (From RateLimitError)\")\n",
    "            print(e)\n",
    "            time.sleep(30)\n",
    "            retry_count += 1\n",
    "\n",
    "            if retry_count >= max_retries:\n",
    "                print(\"Exceeded maximum retries for parsing PDF.... (From RateLimitError)\")\n",
    "                return response\n",
    "\n",
    "\n",
    "    def extract_duration(string):\n",
    "        matches = re.findall(r'\\[\\[([0-9., ]+)\\]\\]', string)\n",
    "        if matches:\n",
    "            # Split by comma and directly convert each element to float\n",
    "            list_of_floats = [float(x.strip()) for x in matches[0].split(\",\")]\n",
    "            return list_of_floats\n",
    "        else:\n",
    "            print(\"No matches found for the pattern.\")\n",
    "            return []  # Fix to return a list directly\n",
    "\n",
    "    def sum_floats_in_list(lst):\n",
    "        if lst != 0:\n",
    "            return math.fsum(lst)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def calculate_yoer(yoer_total, input_string, weightage):\n",
    "\n",
    "        c_total_yr_exp = float(yoer_total)\n",
    "        out_weighted_score = 0\n",
    "        \n",
    "        # Use parse_range to get the lower and upper limits and condition\n",
    "        in_threshold_lower_limit, in_threshold_upper_limit, condition = parse_range(input_string)\n",
    "\n",
    "        # Calculate the candidate's score based on their experience\n",
    "        if c_total_yr_exp < in_threshold_lower_limit:\n",
    "            out_weighted_score = 0  # does not meet requirement\n",
    "        elif in_threshold_lower_limit <= c_total_yr_exp <= in_threshold_upper_limit:\n",
    "            out_weighted_score = 1.0 * weightage  # within range ir equal \n",
    "        elif c_total_yr_exp > in_threshold_upper_limit:\n",
    "            out_weighted_score = 0.5 * weightage  # overqualified\n",
    "        else:\n",
    "            out_weighted_score = 0\n",
    "\n",
    "\n",
    "        return out_weighted_score\n",
    "\n",
    "\n",
    "    response_yoer = extract_yoer_similar(data_dict)\n",
    "    yoer_list = extract_duration(response_yoer)\n",
    "    yoer_total = sum_floats_in_list(yoer_list)\n",
    "    res = calculate_yoer(yoer_total, input, weightage)\n",
    "    print(f\"Candidate: {data_dict['name']}\\t\\t8. Yr of Exp in Role Score:{res}/{weightage}\\t C: {yoer_total} E: {input}\")\n",
    "    \n",
    "    return yoer_total,res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from yoer ChatCompletion(id='chatcmpl-9NNtS2EpRkEq1I7tG45VP7hYMrVfz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Total duration: [[2, 2, 2]]', role='assistant', function_call=None, tool_calls=None))], created=1715360418, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=487, total_tokens=499))\n",
      "Candidate: GOO YE JUI\t\t8. Yr of Exp in Role Score:20.0/20\t C: 6.0 E: >3\n"
     ]
    }
   ],
   "source": [
    "input = \">3\"\n",
    "data_dict[['related_work_experience_duration', 'related_work_experience_duration_score']] = data_dict.apply(lambda row: pd.Series(evaluate_year_exp_role(row, input, 20)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email</th>\n",
       "      <th>local</th>\n",
       "      <th>expected_salary</th>\n",
       "      <th>current_location</th>\n",
       "      <th>education_background</th>\n",
       "      <th>professional_certificate</th>\n",
       "      <th>skill_group</th>\n",
       "      <th>technology_programs_tool</th>\n",
       "      <th>language</th>\n",
       "      <th>previous_job_roles</th>\n",
       "      <th>work_experience_duration</th>\n",
       "      <th>work_experience_duration_score</th>\n",
       "      <th>related_work_experience_duration</th>\n",
       "      <th>related_work_experience_duration_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOO YE JUI</td>\n",
       "      <td>60184040438</td>\n",
       "      <td>yjyejui626@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Country: Malaysia', 'State: Penang', 'City: ...</td>\n",
       "      <td>[{'field_of_study': 'Bachelor Of Computer Scie...</td>\n",
       "      <td>['Microsoft Certified: Azure AI Fundamentals',...</td>\n",
       "      <td>['Full-stack web development', 'Natural Langua...</td>\n",
       "      <td>['HTML 5', 'CSS', 'JavaScript', 'PHP', 'SQL', ...</td>\n",
       "      <td>['English', 'Mandarin', 'Malay', 'French']</td>\n",
       "      <td>[{'job_title': 'Data Science Intern', 'job_com...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  phone_number                 email  local  expected_salary  \\\n",
       "0  GOO YE JUI   60184040438  yjyejui626@gmail.com    NaN              NaN   \n",
       "\n",
       "                                    current_location  \\\n",
       "0  ['Country: Malaysia', 'State: Penang', 'City: ...   \n",
       "\n",
       "                                education_background  \\\n",
       "0  [{'field_of_study': 'Bachelor Of Computer Scie...   \n",
       "\n",
       "                            professional_certificate  \\\n",
       "0  ['Microsoft Certified: Azure AI Fundamentals',...   \n",
       "\n",
       "                                         skill_group  \\\n",
       "0  ['Full-stack web development', 'Natural Langua...   \n",
       "\n",
       "                            technology_programs_tool  \\\n",
       "0  ['HTML 5', 'CSS', 'JavaScript', 'PHP', 'SQL', ...   \n",
       "\n",
       "                                     language  \\\n",
       "0  ['English', 'Mandarin', 'Malay', 'French']   \n",
       "\n",
       "                                  previous_job_roles  \\\n",
       "0  [{'job_title': 'Data Science Intern', 'job_com...   \n",
       "\n",
       "   work_experience_duration  work_experience_duration_score  \\\n",
       "0                      17.0                            20.0   \n",
       "\n",
       "   related_work_experience_duration  related_work_experience_duration_score  \n",
       "0                               6.0                                    20.0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "\n",
    "def evaluate_current_location(data_dict, input, weightage):\n",
    "\n",
    "    dataset_path = 'daerah-working-set.csv'\n",
    "    city_data = pd.read_csv(dataset_path)\n",
    "\n",
    "    def get_coordinates(city_name, country):\n",
    "        # Try to get the coordinates from the dataset\n",
    "        print(\"city name and country\",city_name,country)\n",
    "        try:\n",
    "            city_info = city_data[city_data['Negeri'] == city_name]\n",
    "            if country.lower() == \"malaysia\":\n",
    "                if city_info.empty==True:\n",
    "                    city_info = city_data[city_data['Bandar'] == city_name]\n",
    "                latitude, longitude = city_info['Lat'].values[0], city_info['Lon'].values[0]\n",
    "                print(\"method1\")\n",
    "                return latitude, longitude\n",
    "        except IndexError:\n",
    "            try:\n",
    "                http = urllib3.PoolManager(1, headers={'user-agent': 'cv_parser_geocoder'})\n",
    "                url = f'https://nominatim.openstreetmap.org/search?q={city_name}%2C+Malaysia&format=jsonv2&limit=1'\n",
    "                resp = http.request('GET', url)\n",
    "                loc = json.loads(resp.data.decode())\n",
    "                return loc[0]['lat'],loc[0]['lon']\n",
    "            except:\n",
    "                return None,None\n",
    "            \n",
    "\n",
    "    def get_city_coast(latitude, longitude):\n",
    "        east_coast_range =  (2.618, 6.2733, 101.3765, 103.6015)\n",
    "        north_coast_range = (3.6857, 6.6999, 99.7166, 101.5265)\n",
    "        middle_coast_range = (2.6884, 3.7801, 100.9878, 101.8911)\n",
    "        south_coast_range =  (1.4645, 2.9702, 101.7863, 103.9107)\n",
    "        east_malaysia_range = (1.0104, 6.9244, 109.7889, 119.0566)\n",
    "\n",
    "        try:\n",
    "            # Check which coast the city falls into\n",
    "            if is_in_region(latitude, longitude, east_malaysia_range):\n",
    "                return \"East Malaysia\"\n",
    "            elif is_in_region(latitude, longitude, middle_coast_range):\n",
    "                return \"Middle Coast\"\n",
    "            elif is_in_region(latitude, longitude, east_coast_range):\n",
    "                return \"East Coast\"\n",
    "            elif is_in_region(latitude, longitude, north_coast_range):\n",
    "                return \"North Coast\"\n",
    "            elif is_in_region(latitude, longitude, south_coast_range):\n",
    "                return \"South Coast\"\n",
    "            else:\n",
    "                return \"Out of Malaysia\"\n",
    "        except TypeError:\n",
    "            return \"Location Not Detected\"\n",
    "\n",
    "    def is_in_region(latitude, longitude, region_range):\n",
    "        min_lat, max_lat, min_lon, max_lon = region_range\n",
    "        return min_lat <= latitude <= max_lat and min_lon <= longitude <= max_lon\n",
    "    \n",
    "    state_mapping = {'wilayah persekutuan': 'WP', 'selangor': 'Selangor', 'johor': 'Johor', 'penang': 'Penang', 'pulau pinang': 'Penang', 'sabah': 'Sabah', 'sarawak': 'Sarawak', 'perak': 'Perak', 'kedah': 'Kedah', 'pahang': 'Pahang', 'terengganu': 'Terengganu', 'kelantan': 'Kelantan', 'negeri sembilan': 'N.Sembilan', 'melaka': 'Melaka','melacca': 'Melaka','perlis': 'Perlis'}\n",
    "    \n",
    "    def clean_state(data_dict):\n",
    "        try:\n",
    "            for key, value in state_mapping.items():\n",
    "                if key.lower() in data_dict['current_location'][0]['State'].lower():\n",
    "                    data_dict['current_location'][0]['State'] = value\n",
    "                    break\n",
    "            return data_dict\n",
    "        except:\n",
    "            return data_dict\n",
    "\n",
    "    def clean_location_string(location_str):\n",
    "        try:\n",
    "            # Split the string into city and country\n",
    "            location_parts = list(map(str.strip, location_str.split(',')))\n",
    "\n",
    "            # Handle the case when location_str only has city and country\n",
    "            if len(location_parts) == 2:\n",
    "                state, country = location_parts\n",
    "\n",
    "                for key, value in state_mapping.items():\n",
    "                    if key.lower() in state.lower():\n",
    "                        state = value\n",
    "                        break\n",
    "\n",
    "                city = 'N/A'\n",
    "            elif len(location_parts) == 3:\n",
    "                city, state, country = location_parts\n",
    "\n",
    "                for key, value in state_mapping.items():\n",
    "                    if key.lower() in state.lower():\n",
    "                        state = value\n",
    "                        break\n",
    "            else:\n",
    "                country = location_parts[0]\n",
    "                state = 'N/A'\n",
    "                city = 'N/A'\n",
    "\n",
    "            # Create the result dictionary\n",
    "            result = {'Country': country, 'State': state, 'City': city}\n",
    "\n",
    "            return result\n",
    "        except ValueError:\n",
    "            return location_str\n",
    "    \n",
    "    def evaluate_coordinate(cleaned_location,data_dict):\n",
    "        #Get coordinates for required location and candidate location\n",
    "        latitude1, longitude1 = get_coordinates(cleaned_location['State'],cleaned_location['Country'])\n",
    "        print(latitude1, longitude1)\n",
    "        latitude2, longitude2 = get_coordinates(data_dict['current_location'][0]['State'], data_dict['current_location'][0]['Country'])\n",
    "        print(latitude2, longitude2)\n",
    "        #Define the coast of required location and candidate location\n",
    "        coast1 = get_city_coast(latitude1, longitude1)\n",
    "        coast2 = get_city_coast(latitude2, longitude2)\n",
    "        #Located at the same region(coast)\n",
    "        if coast1 == coast2:\n",
    "            return weightage*0.5\n",
    "        #Located at different region\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def evaluate_location(cleaned_location,data_dict,weightage):\n",
    "        # try:\n",
    "        print(cleaned_location)\n",
    "        print(data_dict['current_location'])\n",
    "        # If candidate is in Malaysia\n",
    "        if cleaned_location['Country'].lower() == \"malaysia\" and data_dict['current_location'][0]['Country'].lower() == \"malaysia\":\n",
    "            # If Option 1 in excel\n",
    "            if cleaned_location['State'].lower() == 'n/a' and cleaned_location['City'].lower() == 'n/a':\n",
    "                return weightage\n",
    "            \n",
    "            # If same state\n",
    "            elif (data_dict['current_location'][0]['State'].lower() == cleaned_location['State'].lower()):\n",
    "                # State = N/A\n",
    "                if cleaned_location['State'].lower() == 'n/a':\n",
    "                    if cleaned_location['City'].lower() == 'n/a':\n",
    "                        return 0\n",
    "                    else:\n",
    "                        print(\"weightage here\")\n",
    "                        return weightage\n",
    "                # State != N/A\n",
    "                else:\n",
    "                    return weightage\n",
    "                \n",
    "            # if not same state\n",
    "            elif (data_dict['current_location'][0]['State'].lower() != cleaned_location['State'].lower()):\n",
    "                # same city\n",
    "                if (data_dict['current_location'][0]['City'].lower() == cleaned_location['City'].lower() == \"N/A\"):\n",
    "                    return 0\n",
    "                else:\n",
    "                    return evaluate_coordinate(cleaned_location,data_dict)\n",
    "                \n",
    "            # if same city\n",
    "            elif (data_dict['current_location'][0]['City'].lower() == cleaned_location['City'].lower()):\n",
    "                # City = N/A\n",
    "                if cleaned_location['City'].lower() == 'n/a':\n",
    "                    return 0\n",
    "                else:\n",
    "                    print(\"weightage here\")\n",
    "                    return weightage\n",
    "            else:\n",
    "                return 0\n",
    "                \n",
    "        # If candidate is overseas\n",
    "        else:\n",
    "            if data_dict['current_location'][0]['Country'] == cleaned_location['Country']:\n",
    "                print(cleaned_location['Country'],data_dict['current_location'][0]['Country'])\n",
    "                return weightage\n",
    "            else:\n",
    "                return 0\n",
    "        # except TypeError as e:\n",
    "        #     print(\"Different Country detected\")\n",
    "        #     print(e)\n",
    "        #     return 0\n",
    "\n",
    "    # Example usage:\n",
    "    cleaned_location = clean_location_string(input)\n",
    "    cleaned_dict = clean_state(data_dict)\n",
    "    out_location_score =  evaluate_location(cleaned_location,cleaned_dict,weightage)\n",
    "    print (f\"Candidate: {data_dict['name']}\\t\\t 11. Location Score: {out_location_score}/{weightage}\\t  E:{cleaned_location} C: {data_dict['current_location']}\\n\")\n",
    "    return out_location_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Country': 'Malaysia', 'State': 'N/A', 'City': 'N/A'}\n",
      "[{'Country': 'Malaysia', 'State': 'Penang', 'City': 'Bukit Mertajam'}]\n",
      "Candidate: GOO YE JUI\t\t 11. Location Score: 10/10\t  E:{'Country': 'Malaysia', 'State': 'N/A', 'City': 'N/A'} C: [{'Country': 'Malaysia', 'State': 'Penang', 'City': 'Bukit Mertajam'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"Malaysia\"\n",
    "\n",
    "data_dict['current_location'][0] = data_dict['current_location'][0].replace(\"'\", '\"')\n",
    "data_dict['current_location'][0] = json.loads(data_dict['current_location'][0])\n",
    "data_dict['current_location_score'] = data_dict.apply(lambda row: evaluate_current_location(row, input,10), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_targetted_employer (data_dict, in_target_employer, in_weightage_employer): \n",
    "    out_targetted_employer_score =  0 \n",
    "    targEmp_industries_included = []\n",
    "\n",
    "    # parse into include and excluded target comapanies \n",
    "    included_input = []\n",
    "    excluded_input = []\n",
    "    exclusion_match = \"\"\n",
    "\n",
    "    def validate_input_format(input_string): \n",
    "        \"\"\"\n",
    "        Check if CVMATCHING template format correct for \n",
    "        Example: \n",
    "            True - \"include(Shell, BP) ,  exclude( KLCC, Novella Clinical, Fidelity Investments)    \n",
    "            True - \"include(), exclude()\"   \n",
    "            True - \"include(Shell, BP) , exclude()\"    \n",
    "            True - \"include() , exclude(Shell, BP)\" \n",
    "            False -  \"include() , exclude(Shell, \" \n",
    "\n",
    "        \"\"\"\n",
    "        # Regular expression pattern to match the valid format\n",
    "        # pattern = r'^(include\\([\\w\\s,]*\\)\\s*,\\s*exclude\\([\\w\\s,]*\\)\\s*)+$'\n",
    "        pattern = r'^(include\\((.*?)\\)\\s*,\\s*exclude\\((.*?)\\)\\s*)+$' # include special characters in company names eg &.\n",
    "        \n",
    "        # Check if the input string matches the pattern\n",
    "        if re.match(pattern, input_string):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def parse_targemp_input (correct_format_inputstring):    \n",
    "        '''\n",
    "            include_input updates to space-removed values \n",
    "            excluded_input updates to space-removed values \n",
    "\n",
    "            Example: \n",
    "            included_input: ['PetronasDigital']\n",
    "            excluded_input: ['KLCC', 'NovellaClinical', 'FidelityInvestments']\n",
    "\n",
    "            Reasoning: \n",
    "            More robust matching when spaces are removed. ExxonMobil matches Exxon Mobil inputted by User \n",
    "        ''' \n",
    "        # Regular expression pattern to match the include and exclude sections\n",
    "        pattern = r'(include|exclude)\\((.*?)\\)'\n",
    "        matches = re.findall(pattern, correct_format_inputstring)\n",
    "\n",
    "        for match in matches:\n",
    "            action, values = match\n",
    "            values_list = [value.strip().replace(\" \", \"\") for value in values.split(',')]\n",
    "            \n",
    "            if action == 'include':\n",
    "                included_input.extend(values_list)\n",
    "            elif action == 'exclude':\n",
    "                excluded_input.extend(values_list)\n",
    "        return True \n",
    "\n",
    "    # Preprocessing input & resume employers \n",
    "    def clean_employer_lst(input_str):\n",
    "        \"\"\"\n",
    "        removes common words for better string matching \n",
    "        \"\"\"\n",
    "        # List of common words to remove\n",
    "        common_words_to_remove = [\"sdn\", \"bhd\", \"berhad\", \"ptd\", \"ltd\", \"inc\", \"co\", \"llc\", \"or\", \"and\", \"&\"]\n",
    "        pattern = r'\\b(?:' + '|'.join(re.escape(word) for word in common_words_to_remove) + r')\\b|-|\\s+'\n",
    "        cleaned_str = re.sub(pattern, '', input_str, flags=re.IGNORECASE)\n",
    "        cleaned_list = [word.strip() for word in cleaned_str.split(',')]\n",
    "        return cleaned_list\n",
    "    \n",
    "    def extract_indsutries (gpt_response): \n",
    "        \"\"\"\n",
    "        Extract industries from customised gpt output response. Example: \n",
    "            gpt_response = \"[[Marketing, Food & Beverage, Shipping, Fashion, Cosmetics]]\"\n",
    "            output = [\"Marketing\", \"Food & Beverage\", \"Shipping\", \"Fashion\", \"Cosmetics\"]\n",
    "        \"\"\"\n",
    "        # Ensure input is a string and follows the expected format\n",
    "        if not isinstance(gpt_response, str) or not gpt_response.startswith(\"[[\") or not gpt_response.endswith(\"]]\"):\n",
    "            return [\"Unknown\"]\n",
    "\n",
    "        # Extract the content inside the outer brackets and split by comma\n",
    "        # The slice [2:-2] removes the outermost brackets \"[[\" and \"]]\"\n",
    "        industries = [industry.strip() for industry in gpt_response[2:-2].split(',')]\n",
    "\n",
    "        return industries\n",
    "    def get_employer_industries_gpt4 (company_name, company_location = \"\"): \n",
    "        max_retries = 5\n",
    "        retry_count = 0\n",
    "        # Classify employer industry by gpt\n",
    "        system_p = f\"\"\"You are a helpful assistant. Given a company name and details, your task is to classify the given company's industry it is involve in as per The International Labour Organization.\n",
    "        1. Classify the industries the company falls into according to The International Labour Organization, based on the company. \n",
    "        2. Output only all of industries in python list.\n",
    "        3. The output format should strictly follow the format in the example provided below - enclosed with double brackets, comma-seperated\n",
    "        4. A company can be classified in more than 1 industries. \n",
    "        Example of the output:\n",
    "            example 1:  [[Marketing, Food & Beverage, Shipping, Fashion, Cosmetics]]\n",
    "            example 2: [[Finance]]\n",
    "            example 3: [[Unknown]] if the company is unfamiliar or you are unsure, output this. \n",
    "\n",
    "        \"\"\"\n",
    "        in_target_employer_petronas_description = \"Petronas is a Malaysian oil and gas company that is involved in upstream and downstream activities. It is the largest oil and gas company in Malaysia, with operations in more than 30 countries around the world. Petronas is involved in exploration, production, refining, marketing, trading, and distribution of petroleum products. It also has interests in petrochemicals, shipping, engineering services, power generation, and other related businesses.\"\n",
    "        p_example = f'[The Start of Company description] {in_target_employer_petronas_description}[The End of Company description] '\n",
    "        p_example_response_format = \"[[Oil and Gas, Petrochemicals, Refining, Retail, Shipping, Exploration and Production, Engineering and Construction]]\"\n",
    "        \n",
    "\n",
    "        p = f'Classify the industries according to The International Labour Organization of the given company. Return results in the aforementioned output format. Given Company: {company_name}, located at {company_location}'\n",
    "        try:\n",
    "            client = OpenAI()\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo-0125\", \n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_p},\n",
    "                    {\"role\": \"user\", \"content\": p_example},\n",
    "                    {\"role\": \"assistant\", \"content\": p_example_response_format},\n",
    "                    {\"role\": \"user\", \"content\": p}\n",
    "                ]\n",
    "            )\n",
    "            try:\n",
    "                result = response.choices[0].message.content\n",
    "                industries_lst = extract_indsutries (result) if result else None \n",
    "                print (f'GPT response on industry: {result}\\tEXTRACTED INDUSTRIES: {industries_lst}')\n",
    "                return industries_lst\n",
    "            except KeyError:\n",
    "                return \"undectected\"\n",
    "        except openai.RateLimitError as e:\n",
    "            print(f\"OpenAI rate limit exceeded. Pausing for one minute before resuming... (From RateLimitError)\")\n",
    "            print(e)\n",
    "            time.sleep(30)\n",
    "            retry_count += 1\n",
    "\n",
    "            if retry_count >= max_retries:\n",
    "                print(\"Exceeded maximum retries for parsing PDF.... (From RateLimitError)\")\n",
    "                return response\n",
    "        except Exception as ire:\n",
    "            print(\"InvalidReqError\",ire)\n",
    "            return \"undetected\"\n",
    "\n",
    "    \n",
    "    def check_if_matching_employer_industry():\n",
    "        '''\n",
    "            Input: \n",
    "                user_input_bool: True if input is a list (ie from CVMatching xlsx since can be >1 company)\n",
    "                in_target_employer: Company Name\n",
    "            Used when candidate has not work in target employer specified, check for matching industries: \n",
    "                1. Ask GPT to classify the industries based on this description \n",
    "                2. Check against candidate's previous job company industries\n",
    "                3. if candidate worked in similar industries: 50%, else 0%\n",
    "        '''\n",
    "        # variables\n",
    "        out_targetted_employer_score =  0\n",
    "\n",
    "\n",
    "        if (targEmp_industries_included == []): \n",
    "            init_input_employer_industry()\n",
    "\n",
    "        candidate_industries = data_dict[\"Industries\"]\n",
    "        \n",
    "        # find matches between overall industries and included()\n",
    "        list1 = [x.lower().replace(\" \", \"\") for x in candidate_industries if x.lower().replace(\" \", \"\") != \"unknown\"]   \n",
    "        list2 = [x.lower().replace(\" \", \"\") for x in targEmp_industries_included if x.lower().replace(\" \", \"\") != \"unknown\"]\n",
    "        matches = [x for x in list1 if x in list2]\n",
    "\n",
    "        print(f\"GPT-ed Classified Industries.\\t Included:{included_input} \\tExcluded {excluded_input}. Included Industries{targEmp_industries_included}\\t Candidate's data_dict['Industries']: {candidate_industries}\\t Matched industries are: {matches}\")\n",
    "        if matches:\n",
    "            print (f\"Candidate: {data_dict['name']}\\t\\t 12. Targeted Employer Score: {out_targetted_employer_score}/{in_weightage_employer}\\t Result: Case 2: Matching Industries are {matches}\\n\")\n",
    "            res_employer = f\"Matching industries detected: {matches}\"\n",
    "            res_employer_score = 0.5*float(in_weightage_employer)\n",
    "            return res_employer,res_employer_score\n",
    "        else:\n",
    "            print (f\"Candidate: {data_dict['name']}\\t\\t 12. Targeted Employer Score: {out_targetted_employer_score}/{in_weightage_employer}\\t Result: Case 3: NO MATCHING INDUSTRY \\n \")\n",
    "            res_employer = f\"No exact match and no matching industry from past employers detected\"\n",
    "            res_employer_score = 0\n",
    "            return res_employer,res_employer_score\n",
    "\n",
    "    def worked_in_excluded(candidate_employers, excluded): \n",
    "        excluded_matches = []\n",
    "        for x in candidate_employers:\n",
    "                if x in excluded:\n",
    "                    excluded_matches = f\"Exclusion detected[{x}]\"\n",
    "                    return excluded_matches, True \n",
    "        return excluded_matches, False      \n",
    "    \n",
    "    def init_input_employer_industry ():\n",
    "        \"\"\"\n",
    "        Initialises list for related-industries in criteria file by user\n",
    "        \n",
    "        \"\"\" \n",
    "        target_employer_industries = set()\n",
    "        for employer in included_input:\n",
    "            print(f\"xlsx included employer {employer}\")\n",
    "            if employer: \n",
    "                a = get_employer_industries_gpt4(employer)\n",
    "                target_employer_industries.update(a)\n",
    "        # Assuming 'target_employer_industries_lst' is a list of lists (each inner list contains industries for an employer)\n",
    "        targEmp_industries_included = list (target_employer_industries)\n",
    "        print (f\"RESUME PARSER CLASS INTIALISED: XLSX Target Employer related googlesearch industries.\\tIncluded {included_input}\\t self.targEmp_industries: {targEmp_industries_included}\\n\")\n",
    "        return True \n",
    "                \n",
    "    # User/Employer Template input validation\n",
    "    try:\n",
    "        # Assuming validate_input_format raises an exception if validation fails\n",
    "        if not validate_input_format(in_target_employer):\n",
    "            raise ValueError(\"CVMatching Template.xlsx input string is invalid at 12.Target Employer\")\n",
    "\n",
    "        # If validation passes, proceed with parsing\n",
    "        parse_targemp_input(in_target_employer)  # included, excluded is updated\n",
    "        print(f\"included: {included_input}, \\t excluded: {excluded_input}\")\n",
    "    except ValueError as e:\n",
    "        # Handle the validation error\n",
    "        error_message = f\"Warning, 12. Target Employer in file CVMatching Template.xlsx {e}\"\n",
    "        print(error_message)\n",
    "        # self.targEmp_exclusion_matched = \"CVMatching Template.xlsx input string is invalid at 12.Target Employer\"\n",
    "        return -1\n",
    "        \n",
    "    # Preprocessing inputs \n",
    "    req_employers = clean_employer_lst(\"\".join(included_input))  # clean input from excel from common words \n",
    "    candidate_employers = clean_employer_lst(\",\".join([role[\"job_company\"] for role in data_dict[\"previous_job_roles\"] if isinstance(role, dict)]))\n",
    "    print(f\"12. Evaluating Target Employer\\tIncluded: {included_input} \\t excluded: {excluded_input}\\tCandidate's previous employers: {candidate_employers}\")\n",
    "\n",
    "    # Preprocessing Data_dict of candidate: Reassign GPT classified industries for candidate's each previous employer \n",
    "    overall_industries = set()\n",
    "    for x in data_dict[\"previous_job_roles\"]:\n",
    "        if isinstance(x, dict):\n",
    "            q = x['job_company'] \n",
    "            l = x[\"job_location\"] \n",
    "            industries_list = get_employer_industries_gpt4(q, l)  # This now returns a list directly\n",
    "            \n",
    "            # Directly assign the list without splitting\n",
    "            x[\"Industries\"] = industries_list\n",
    "            \n",
    "            # Update overall industries without needing to split; handle single-value lists correctly\n",
    "            overall_industries.update([j.strip().strip('.') for j in industries_list])\n",
    "            \n",
    "            # Adjust the print statement to directly use industries_list\n",
    "            print(f\"{q} located at {l} is gpt-classified as a company in industries: {industries_list}\")\n",
    "            \n",
    "    data_dict[\"Industries\"] = list(overall_industries)\n",
    "    # Scoring Method\n",
    "    # 1. Check if candidate work in excluded companies \n",
    "    exclusion_match, excluded_flag = worked_in_excluded(candidate_employers, excluded_input)\n",
    "    if excluded_flag:\n",
    "        return exclusion_match,0\n",
    "    else:\n",
    "        # 2. Check for exact match with cleaned lists (employer and user)\n",
    "        matched_employer = []\n",
    "        for candidate in candidate_employers:\n",
    "            # Skip if candidate is empty or whitespace\n",
    "            if not candidate.strip():\n",
    "                continue\n",
    "\n",
    "            for required in req_employers:\n",
    "                if re.search(fr'{re.escape(candidate)}', required, re.IGNORECASE):\n",
    "                    matched_employer.append(candidate)\n",
    "                    break # breaks right after matching 1 employer\n",
    "                \n",
    "        if not matched_employer:# 3: Check for related industry in candidate's past employers \n",
    "            print ('\\t...12. Target Employer: Checking for any past employers matching to industry of target employer')\n",
    "            return check_if_matching_employer_industry()\n",
    "            \n",
    "        else: # exact match employer \n",
    "            print (f\"Candidate: {data_dict['name']}\\t\\t 12. Targeted Employer Score: {out_targetted_employer_score}/{in_weightage_employer}\\t  Result: Case 1: MATCHING EMPLOYER \\t Matches = {matched_employer}\\n)\")\n",
    "            res_employer =  f\"Inclusion detected: {matched_employer}\"\n",
    "            res_employer_score = float(in_weightage_employer)\n",
    "    return res_employer,res_employer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included: ['Shell', 'BP'], \t excluded: ['']\n",
      "12. Evaluating Target Employer\tIncluded: ['Shell', 'BP'] \t excluded: ['']\tCandidate's previous employers: ['PetronasDigital']\n",
      "GPT response on industry: [[Unknown]]\tEXTRACTED INDUSTRIES: ['Unknown']\n",
      "Petronas Digital Sdn Bhd located at N/A is gpt-classified as a company in industries: ['Unknown']\n",
      "\t...12. Target Employer: Checking for any past employers matching to industry of target employer\n",
      "xlsx included employer Shell\n",
      "GPT response on industry: [[Oil and Gas, Petrochemicals, Refining, Retail, Shipping, Exploration and Production, Engineering and Construction, Energy]]\tEXTRACTED INDUSTRIES: ['Oil and Gas', 'Petrochemicals', 'Refining', 'Retail', 'Shipping', 'Exploration and Production', 'Engineering and Construction', 'Energy']\n",
      "xlsx included employer BP\n",
      "GPT response on industry: [[Oil and Gas, Petrochemicals, Refining, Retail, Shipping, Exploration and Production, Engineering and Construction]]\tEXTRACTED INDUSTRIES: ['Oil and Gas', 'Petrochemicals', 'Refining', 'Retail', 'Shipping', 'Exploration and Production', 'Engineering and Construction']\n",
      "RESUME PARSER CLASS INTIALISED: XLSX Target Employer related googlesearch industries.\tIncluded ['Shell', 'BP']\t self.targEmp_industries: ['Shipping', 'Energy', 'Engineering and Construction', 'Oil and Gas', 'Refining', 'Retail', 'Exploration and Production', 'Petrochemicals']\n",
      "\n",
      "GPT-ed Classified Industries.\t Included:['Shell', 'BP'] \tExcluded ['']. Included Industries[]\t Candidate's data_dict['Industries']: ['Unknown']\t Matched industries are: []\n",
      "Candidate: GOO YE JUI\t\t 12. Targeted Employer Score: 0/20\t Result: Case 3: NO MATCHING INDUSTRY \n",
      " \n"
     ]
    }
   ],
   "source": [
    "input = \"include(Shell, BP) , exclude()\"\n",
    "# data_dict['previous_job_roles'][0] = data_dict['previous_job_roles'][0].replace(\"'\", '\"')\n",
    "# data_dict['previous_job_roles'][0] = json.loads(data_dict['previous_job_roles'][0])\n",
    "data_dict[['targeted_employer', 'targeted_employer_score']] = data_dict.apply(lambda row: pd.Series(evaluate_targetted_employer(row, input, 20)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import traceback\n",
    "\n",
    "def evaluate_language_score(data_dict, input, weightage):\n",
    "    match_percentage = 0\n",
    "    try:\n",
    "        custom_languages = [\"Bahasa Melayu\", \"Bahasa Malaysia\", \"Malay\", \"Melayu\", \"Bahasa\"]\n",
    "        def check_custom_languages(input_list):\n",
    "            return set(lang.lower()for lang in custom_languages if lang.lower() in input_list)\n",
    "        \n",
    "        languages_str = ', '.join(data_dict['language'])\n",
    "\n",
    "        nlp = spacy.load('en_core_web_md')\n",
    "        \n",
    "        def get_lang_detector(nlp, name):\n",
    "            return LanguageDetector()\n",
    "\n",
    "        if languages_str == \"N, /, A\" or languages_str == \"N/A\":\n",
    "            Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "            nlp.add_pipe('language_detector', last=True)\n",
    "            doc1 = nlp(str(data_dict))\n",
    "            if doc1._.language['language']=='en':\n",
    "                languages_str='English'\n",
    "                data_dict['language'] = ['English']\n",
    "        doc1 = nlp(languages_str)\n",
    "        doc2 = nlp(input)\n",
    "        \n",
    "        languages1 = set(ent.text.strip() for ent in doc1.ents if ent.label_ == \"LANGUAGE\")\n",
    "        languages2 = set(ent.text.strip() for ent in doc2.ents if ent.label_ == \"LANGUAGE\")\n",
    "\n",
    "        languages1.update(check_custom_languages(languages_str))\n",
    "        languages2.update(check_custom_languages(input))\n",
    "\n",
    "        matched_languages = set(l.lower() for l in languages1).intersection(set(l.lower() for l in languages2))\n",
    "\n",
    "        # Calculate the percentage of matches\n",
    "        if languages1:\n",
    "            match_percentage = len(matched_languages) / len(languages2) * 100\n",
    "        else:\n",
    "            match_percentage = 0\n",
    "        language_score = round(match_percentage/100*weightage)\n",
    "        print(\"Matched Languages: \",matched_languages)\n",
    "        print (f\"Candidate: {data_dict['name']}\\t\\t 14. Language Score: {language_score}/{weightage}\\t C:{languages1} {languages_str}, E: {input} \\n\")\n",
    "        \n",
    "        return language_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error on language\",e)\n",
    "        traceback.print_exc()  # This will print the traceback information\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Languages:  {'mandarin', 'english'}\n",
      "Candidate: GOO YE JUI\t\t 14. Language Score: 7/10\t C:{'Mandarin', 'English'} English, Mandarin, Malay, French, E: English, Malay, Mandarin \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"English, Malay, Mandarin\"\n",
    "\n",
    "# data_dict['language'][0] = data_dict['language'][0].replace(\"'\", '\"')\n",
    "# data_dict['language'][0] = json.loads(data_dict['language'][0])\n",
    "data_dict['language_score'] = data_dict.apply(lambda row: evaluate_language_score(row, input,10), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 \n",
    "def evaluate_salary_score(data_dict, input, weightage):\n",
    "    \"\"\"\n",
    "    Checks if the candidate's expected salary matches the employer's range.\n",
    "\n",
    "    Args:\n",
    "    in_salary (str): Employer's expected salary range.\n",
    "    c_exp_salary (str): Candidate's expected salary.\n",
    "\n",
    "    Returns:\n",
    "    int: Score indicating the match percentage.\n",
    "    \"\"\"\n",
    "    # Assign 0 score for N/A or empty values\n",
    "    if np.isnan(data_dict['expected_salary']):\n",
    "        out_salary_score = 0\n",
    "    else: \n",
    "        # Parse employer's expected salary range\n",
    "        in_exp_sal_llimit, in_exp_sal_ulimit, in_exp_sal_condition = parse_range(input)\n",
    "\n",
    "        # Parse candidate's expected salary, calculate average if it's a range\n",
    "        c_exp_sal = 0 # default is 0 \n",
    "        c_exp_sal_llimit, c_exp_sal_ulimit, c_exp_sal_condition = parse_range(data_dict['expected_salary'])\n",
    "        if c_exp_sal_llimit != c_exp_sal_ulimit:\n",
    "            # Alternative: Calculate average for a range\n",
    "                # c_exp_sal = (c_exp_sal_llimit + c_exp_sal_ulimit) / 2  \n",
    "            c_exp_sal = c_exp_sal_llimit # assume lower limit when cv states sal range for now \n",
    "        else:\n",
    "            c_exp_sal = c_exp_sal_llimit  # Use lower limit as single value if cv input not a range\n",
    "\n",
    "        # Check if the candidate's expected salary falls within the employer's range\n",
    "        if in_exp_sal_llimit <= c_exp_sal <= in_exp_sal_ulimit:\n",
    "            res = 1  # 100% \n",
    "        else:\n",
    "            res = 0\n",
    "        \n",
    "        out_salary_score = res * weightage\n",
    "\n",
    "    print (f\"Candidate: {data_dict['name']}\\t\\t 15. Exp Salary in RM Score: {out_salary_score}\\t Employer: {input}, Candidate: {data_dict['expected_salary']}\\n \")\n",
    "\n",
    "    return out_salary_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate: GOO YE JUI\t\t 15. Exp Salary in RM Score: 0\t Employer: 3000, Candidate: nan\n",
      " \n"
     ]
    }
   ],
   "source": [
    "input = \"3000\"\n",
    "data_dict['expected_salary_score'] = data_dict.apply(lambda row: evaluate_salary_score(row, input,10), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email</th>\n",
       "      <th>local</th>\n",
       "      <th>expected_salary</th>\n",
       "      <th>current_location</th>\n",
       "      <th>education_background</th>\n",
       "      <th>professional_certificate</th>\n",
       "      <th>skill_group</th>\n",
       "      <th>technology_programs_tool</th>\n",
       "      <th>language</th>\n",
       "      <th>previous_job_roles</th>\n",
       "      <th>current_location_score</th>\n",
       "      <th>targeted_employer</th>\n",
       "      <th>targeted_employer_score</th>\n",
       "      <th>language_score</th>\n",
       "      <th>expected_salary_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOO YE JUI</td>\n",
       "      <td>60184040438</td>\n",
       "      <td>yjyejui626@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'Country': 'Malaysia', 'State': 'Penang', 'C...</td>\n",
       "      <td>[{'field_of_study': 'Bachelor Of Computer Scie...</td>\n",
       "      <td>['Microsoft Certified: Azure AI Fundamentals',...</td>\n",
       "      <td>['Full-stack web development', 'Natural Langua...</td>\n",
       "      <td>['HTML 5', 'CSS', 'JavaScript', 'PHP', 'SQL', ...</td>\n",
       "      <td>[English, Mandarin, Malay, French]</td>\n",
       "      <td>[{'job_title': 'Data Science Intern', 'job_com...</td>\n",
       "      <td>10</td>\n",
       "      <td>No exact match and no matching industry from p...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  phone_number                 email  local  expected_salary  \\\n",
       "0  GOO YE JUI   60184040438  yjyejui626@gmail.com    NaN              NaN   \n",
       "\n",
       "                                    current_location  \\\n",
       "0  [{'Country': 'Malaysia', 'State': 'Penang', 'C...   \n",
       "\n",
       "                                education_background  \\\n",
       "0  [{'field_of_study': 'Bachelor Of Computer Scie...   \n",
       "\n",
       "                            professional_certificate  \\\n",
       "0  ['Microsoft Certified: Azure AI Fundamentals',...   \n",
       "\n",
       "                                         skill_group  \\\n",
       "0  ['Full-stack web development', 'Natural Langua...   \n",
       "\n",
       "                            technology_programs_tool  \\\n",
       "0  ['HTML 5', 'CSS', 'JavaScript', 'PHP', 'SQL', ...   \n",
       "\n",
       "                             language  \\\n",
       "0  [English, Mandarin, Malay, French]   \n",
       "\n",
       "                                  previous_job_roles  current_location_score  \\\n",
       "0  [{'job_title': 'Data Science Intern', 'job_com...                      10   \n",
       "\n",
       "                                   targeted_employer  targeted_employer_score  \\\n",
       "0  No exact match and no matching industry from p...                        0   \n",
       "\n",
       "   language_score  expected_salary_score  \n",
       "0               7                      0  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prof_cert_phrase(data_dict, input, weightage):\n",
    "\n",
    "    def detect_match_phrases(resume, match_phrases):\n",
    "        matches = []\n",
    "        for phrase in match_phrases:\n",
    "            print(\"phrase\",phrase)\n",
    "            if type(phrase) == list:\n",
    "                for x in phrase:\n",
    "                    print(\"printing x\",x)\n",
    "                    pattern = re.compile(fr'\\b{re.escape(x)}\\b', re.IGNORECASE)\n",
    "                    matches.extend(pattern.findall(resume.lower()))\n",
    "                    print(\"printing matches\",matches)\n",
    "            else:\n",
    "                # Use case-insensitive matching and convert to lowercase\n",
    "                print(phrase)\n",
    "                pattern = re.compile(fr'{phrase}', re.IGNORECASE)\n",
    "                print(pattern)\n",
    "                print(\"resume\",resume)\n",
    "                matches.extend(pattern.findall(resume.lower()))\n",
    "\n",
    "        # Remove duplicates by converting the list to a set and back to a list\n",
    "        unique_matches = list(set(matches))\n",
    "\n",
    "        return unique_matches\n",
    "    \n",
    "    def evaluate_candidate_score(matched_phrases, match_phrase_input, weightage):\n",
    "        # Calculate the score based on the weightage\n",
    "        score = round(len(matched_phrases) / len(match_phrase_input) * weightage,2)\n",
    "\n",
    "        return score\n",
    "    \n",
    "\n",
    "    # Read the abbreviation CSV file\n",
    "    # file_path = os.path.join(os.path.dirname(__file__), 'CVMatching_Prof_Cert_Wikipedia.xlsx')\n",
    "    file_path = 'CVMatching_Prof_Cert_Wikipedia.xlsx'\n",
    "    abb_csv = pd.read_excel(file_path)\n",
    "    abb_csv = abb_csv[['Name', 'Abbreviation']]\n",
    "    abb_csv = abb_csv.dropna(subset=['Abbreviation']).reset_index(drop=True)\n",
    "\n",
    "    abb_csv['Name_lower'] = abb_csv['Name'].str.lower()\n",
    "    unique_elements = [ue.strip() for ue in input.split(\",\")]\n",
    "\n",
    "    # Retrieve 'Professional Certificate' field from data_dict\n",
    "    professional_certificates = data_dict['professional_certificate']\n",
    "    \n",
    "    for phrase in unique_elements.copy():\n",
    "        # Convert the current phrase to lowercase for case-insensitive comparison\n",
    "        phrase_lower = phrase.lower()\n",
    "        \n",
    "        # Check if the lowercase phrase is an exact match in any lowercase entry in the 'Name' or 'Abbreviation' columns\n",
    "        match = abb_csv[(abb_csv['Name_lower'] == phrase_lower) | (abb_csv['Abbreviation'].str.lower() == phrase_lower)]\n",
    "        \n",
    "        # If there is a match, remove both the abbreviation and the full name from the unique elements\n",
    "        if not match.empty:\n",
    "            # Update with matched abbreviations and names\n",
    "            unique_elements.append([match['Name'].values[0],match['Abbreviation'].values[0]])\n",
    "            unique_elements.remove(phrase)\n",
    "\n",
    "    # Convert data_dict to a string\n",
    "    data_dict_str = ''.join(professional_certificates)\n",
    "\n",
    "    # Detect matched phrases\n",
    "    matched_phrases = detect_match_phrases(data_dict_str, unique_elements)\n",
    "    print('matched_phrases', matched_phrases,len(matched_phrases))\n",
    "    print('unique_elements', unique_elements,len(unique_elements))\n",
    "    # Evaluate candidate score\n",
    "    score = evaluate_candidate_score(matched_phrases, unique_elements, weightage)\n",
    "    \n",
    "    print (f\"Candidate: {data_dict['name']}\\t\\t 10. Prof Cert Score: {score}/{weightage}\\t Employer's Certs: {input},  Candidate's Certs: {professional_certificates}\\n \")\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase Microsoft Certified: Azure AI Fundamentals\n",
      "Microsoft Certified: Azure AI Fundamentals\n",
      "re.compile('Microsoft Certified: Azure AI Fundamentals', re.IGNORECASE)\n",
      "resume ['Microsoft Certified: Azure AI Fundamentals', 'Google Data Analytics Certificate by Coursera', 'Alteryx Foundational Micro-Credential', 'Alteryx Designer Core Certification', 'AWS Academy Graduate - AWS Academy Cloud Foundations', 'AWS Academy Graduate - AWS Academy Machine Learning Foundations', 'AWS Academy Graduate - AWS Academy Data Analytics', 'AWS Academy Graduate - AWS Academy Machine Learning for Natural Language Processing', 'AWS Academy Graduate - AWS Academy Data Engineering', 'AWS Academy Graduate - AWS Academy Cloud Web Application Builder', 'AWS Academy Graduate - AWS Academy Cloud Data Pipeline Builder']\n",
      "phrase ['Chartered Financial Analyst', 'CFA']\n",
      "printing x Chartered Financial Analyst\n",
      "printing matches ['microsoft certified: azure ai fundamentals']\n",
      "printing x CFA\n",
      "printing matches ['microsoft certified: azure ai fundamentals']\n",
      "matched_phrases ['microsoft certified: azure ai fundamentals'] 1\n",
      "unique_elements ['Microsoft Certified: Azure AI Fundamentals', ['Chartered Financial Analyst', 'CFA']] 2\n",
      "Candidate: GOO YE JUI\t\t 10. Prof Cert Score: 5.0/10\t Employer's Certs: CFA, Microsoft Certified: Azure AI Fundamentals,  Candidate's Certs: ['Microsoft Certified: Azure AI Fundamentals', 'Google Data Analytics Certificate by Coursera', 'Alteryx Foundational Micro-Credential', 'Alteryx Designer Core Certification', 'AWS Academy Graduate - AWS Academy Cloud Foundations', 'AWS Academy Graduate - AWS Academy Machine Learning Foundations', 'AWS Academy Graduate - AWS Academy Data Analytics', 'AWS Academy Graduate - AWS Academy Machine Learning for Natural Language Processing', 'AWS Academy Graduate - AWS Academy Data Engineering', 'AWS Academy Graduate - AWS Academy Cloud Web Application Builder', 'AWS Academy Graduate - AWS Academy Cloud Data Pipeline Builder']\n",
      " \n"
     ]
    }
   ],
   "source": [
    "input = \"CFA, Microsoft Certified: Azure AI Fundamentals\"\n",
    "data_dict['expected_salary_score'] = data_dict.apply(lambda row: evaluate_prof_cert_phrase(row, input,10), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_year_grad_score(data_dict, input_year, weightage): \n",
    "    out_yr_grad  =  0 \n",
    "\n",
    "    if 'education_background' not in data_dict:\n",
    "        print(\"No educational background provided.\")\n",
    "        return \"No educational background provided.\",0\n",
    "    else: \n",
    "        # Sort education background by year of graduation once, after preprocessing\n",
    "        data_list = ast.literal_eval(data_dict.education_background)\n",
    "        print(data_list)\n",
    "        data_list.sort(key=lambda x: int(x['year_of_graduation']), reverse=True)\n",
    "        # Preprocess and validate year of graduation entries\n",
    "        res = \"\"\n",
    "        for edu in data_list:\n",
    "            year_of_graduation = str(edu['year_of_graduation'])  # Ensure it's a string for comparison\n",
    "            print(year_of_graduation)\n",
    "            if not year_of_graduation.isdigit() and year_of_graduation.lower() not in ['present', 'current']:\n",
    "                edu['year_of_graduation'] = 'N/A'\n",
    "            elif year_of_graduation.lower() in ['present', 'current']:\n",
    "                edu['year_of_graduation'] = 'Still Studying'\n",
    "\n",
    "            year_of_graduation = str(edu['year_of_graduation']) \n",
    "            res += year_of_graduation + \", \"\n",
    "            if year_of_graduation == input_year:\n",
    "                out_yr_grad = weightage\n",
    "\n",
    "        # Print the result\n",
    "        res = res if res else \"Not Specified\" \n",
    "        print(f\"16. Year of Grad: {out_yr_grad}\\t Employer: {input_year},  Candidate: {res}\")\n",
    "\n",
    "    return res,out_yr_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'field_of_study': 'Bachelor Of Computer Science (Data Engineering)', 'level': \"Bachelor's Degree\", 'cgpa': '3.97', 'university': 'Universiti Teknologi Malaysia', 'start_date': '2020', 'year_of_graduation': '2024'}, {'field_of_study': 'Foundation in Science', 'level': 'Foundation', 'cgpa': '3.78', 'university': 'Universiti Teknologi Malaysia', 'start_date': '2019', 'year_of_graduation': '2020'}]\n",
      "2024\n",
      "2020\n",
      "16. Year of Grad: 20\t Employer: 2024,  Candidate: 2024, 2020, \n"
     ]
    }
   ],
   "source": [
    "input = \"2024\"\n",
    "data_dict[['year_of_graduation', 'year_of_graduation_score']] = data_dict.apply(lambda row: pd.Series(evaluate_year_grad_score(row, input, 20)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email</th>\n",
       "      <th>local</th>\n",
       "      <th>expected_salary</th>\n",
       "      <th>current_location</th>\n",
       "      <th>education_background</th>\n",
       "      <th>professional_certificate</th>\n",
       "      <th>skill_group</th>\n",
       "      <th>technology_programs_tool</th>\n",
       "      <th>language</th>\n",
       "      <th>previous_job_roles</th>\n",
       "      <th>current_location_score</th>\n",
       "      <th>targeted_employer</th>\n",
       "      <th>targeted_employer_score</th>\n",
       "      <th>language_score</th>\n",
       "      <th>expected_salary_score</th>\n",
       "      <th>year_of_graduation_score</th>\n",
       "      <th>year_of_graduation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOO YE JUI</td>\n",
       "      <td>60184040438</td>\n",
       "      <td>yjyejui626@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'Country': 'Malaysia', 'State': 'Penang', 'C...</td>\n",
       "      <td>[{'field_of_study': 'Bachelor Of Computer Scie...</td>\n",
       "      <td>['Microsoft Certified: Azure AI Fundamentals',...</td>\n",
       "      <td>['Full-stack web development', 'Natural Langua...</td>\n",
       "      <td>['HTML 5', 'CSS', 'JavaScript', 'PHP', 'SQL', ...</td>\n",
       "      <td>[English, Mandarin, Malay, French]</td>\n",
       "      <td>[{'job_title': 'Data Science Intern', 'job_com...</td>\n",
       "      <td>10</td>\n",
       "      <td>No exact match and no matching industry from p...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2024, 2020,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  phone_number                 email  local  expected_salary  \\\n",
       "0  GOO YE JUI   60184040438  yjyejui626@gmail.com    NaN              NaN   \n",
       "\n",
       "                                    current_location  \\\n",
       "0  [{'Country': 'Malaysia', 'State': 'Penang', 'C...   \n",
       "\n",
       "                                education_background  \\\n",
       "0  [{'field_of_study': 'Bachelor Of Computer Scie...   \n",
       "\n",
       "                            professional_certificate  \\\n",
       "0  ['Microsoft Certified: Azure AI Fundamentals',...   \n",
       "\n",
       "                                         skill_group  \\\n",
       "0  ['Full-stack web development', 'Natural Langua...   \n",
       "\n",
       "                            technology_programs_tool  \\\n",
       "0  ['HTML 5', 'CSS', 'JavaScript', 'PHP', 'SQL', ...   \n",
       "\n",
       "                             language  \\\n",
       "0  [English, Mandarin, Malay, French]   \n",
       "\n",
       "                                  previous_job_roles  current_location_score  \\\n",
       "0  [{'job_title': 'Data Science Intern', 'job_com...                      10   \n",
       "\n",
       "                                   targeted_employer  targeted_employer_score  \\\n",
       "0  No exact match and no matching industry from p...                        0   \n",
       "\n",
       "   language_score  expected_salary_score  year_of_graduation_score  \\\n",
       "0               7                    5.0                        20   \n",
       "\n",
       "  year_of_graduation  \n",
       "0       2024, 2020,   "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "def gpt_recommendation_summary(data_dict):\n",
    "    max_retries = 5\n",
    "    retry_count = 0\n",
    "    \n",
    "    data_df = pd.DataFrame.from_dict([data_dict])\n",
    "    df = data_df[['education_background', 'skill_group',\n",
    "    'technology_programs_tool',\n",
    "    'previous_job_roles', 'professional_certificate', 'language']]\n",
    "    candidate_info = df.to_dict()\n",
    "    \n",
    "    try:\n",
    "        yoer_prompt_system = f\"\"\"[Instruction]\n",
    "        You are the {job_title} recruiter, state all the alignments and misalignments of the candidate's qualifications and experience with the job description, and job requirements.\n",
    "\n",
    "        [Question]\n",
    "        - [Job Description]\n",
    "        {job_description}\n",
    "        - [Job Requirements]\n",
    "        {job_requirement}\n",
    "        \"\"\"\n",
    "\n",
    "        yoer_prompt_user = f\"\"\"\n",
    "        {candidate_info}\n",
    "        \"\"\"\n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\", # 3.5 turbo \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": yoer_prompt_system},\n",
    "                {\"role\": \"user\", \"content\": yoer_prompt_user}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"OpenAI rate limit exceeded. Pausing for one minute before resuming... (From RateLimitError)\")\n",
    "        print(e)\n",
    "        time.sleep(30)\n",
    "        retry_count += 1\n",
    "        response = \"Error\"\n",
    "\n",
    "        if retry_count >= max_retries:\n",
    "            print(\"Exceeded maximum retries for parsing PDF.... (From RateLimitError)\")\n",
    "            return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['gpt_recommendation_summary'] = data_dict.apply(lambda row: gpt_recommendation_summary(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Alignments:**\n",
      "1. **Education Background:** The candidate holds a Bachelor's degree in Computer Science, which aligns with the job requirement of a Bachelor's degree in Computer Science, Statistics, Mathematics, or a related field.\n",
      "2. **Skill Set:** The candidate has skills in Python, SQL, and data analysis, which are required for the job. Additionally, the candidate's experience with Python aligns with the job requirement of proficiency in programming languages such as Python, R, or SQL.\n",
      "3. **Professional Certificates:** The candidate has various certifications related to data analytics and machine learning, which demonstrate a commitment to continuous learning and align with the job requirement of staying current with the latest developments in data science and technology.\n",
      "\n",
      "**Misalignments:**\n",
      "1. **Education Background:** The candidate's field of study is more focused on Data Engineering, which may not directly align with the preferred fields of Computer Science, Statistics, or Mathematics specified in the job requirements.\n",
      "2. **Experience:** The candidate's experience as a Data Science Intern may not meet the requirement of having a few years of experience in data science or a related field, with a proven track record of leading successful projects and initiatives.\n",
      "3. **Technology/Programs/Tools:** While the candidate has a diverse range of technology skills, some of them may not directly align with the technologies preferred by the job, such as Hadoop, Spark, or cloud platforms like AWS, Azure, or GCP.\n",
      "4. **Language Skills:** The candidate's language skills in Mandarin, Malay, and French are not mentioned in the job requirements, although they can be beneficial in certain contexts, they are not directly related to the job requirements.\n"
     ]
    }
   ],
   "source": [
    "print(data_dict['gpt_recommendation_summary'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
